# CHECK LIST: Разработка Telegram Parser Service

> **Этот файл — подробный чек-лист разработки микросервиса parsing-service согласно техническому заданию. Каждый пункт должен быть выполнен и протестирован перед переходом к следующему этапу. Отмечайте выполненные задачи галочкой [x].**

---

## ЭТАП 1: Подготовка инфраструктуры и настройка базовых компонентов

### 1.1. Анализ и переработка архитектуры
- [ ] Проанализировать существующий код parsing-service
- [ ] Создать план миграции от универсального парсера к Telegram-специфичному
- [ ] Определить структуру новых моделей данных для Telegram
- [ ] Спроектировать API endpoints согласно ТЗ
- [ ] Создать схему интеграции с Integration Service
- [ ] Документировать архитектурные решения в PARSING-SERVICE-PROJECT.md

### 1.2. Настройка базы данных PostgreSQL
- [ ] Создать отдельную БД для parsing-service (parsing_db)
- [ ] Настроить пользователя parsing_user с необходимыми правами
- [ ] Обновить строку подключения в docker-compose.yml
- [ ] Создать новые модели SQLAlchemy для Telegram данных:
  - [ ] ParseTask (задачи парсинга)
  - [ ] ParseResult (результаты парсинга)  
  - [ ] TelegramChat (информация о чатах)
  - [ ] TelegramUser (пользователи из чатов)
  - [ ] TelegramMessage (сообщения, при необходимости)
  - [ ] ParseLog (логи выполнения)
- [ ] Создать и выполнить Alembic миграции
- [ ] Добавить индексы для оптимизации запросов
- [ ] Протестировать создание и чтение данных

### 1.3. Интеграция с RabbitMQ (очереди задач)
- [ ] Настроить Celery для работы с RabbitMQ
- [ ] Создать очереди для разных приоритетов (low, normal, high)
- [ ] Реализовать структуру задач согласно ТЗ:
  - [ ] user_id, link, type, account_id, resume_point, status
- [ ] Настроить celeryconfig.py с правильными настройками
- [ ] Создать базовую Celery задачу для тестирования
- [ ] Протестировать отправку и получение задач из очереди

### 1.4. Интеграция с Redis (состояния и кэш)
- [ ] Настроить подключение к Redis для хранения состояний
- [ ] Реализовать класс для управления состояниями задач
- [ ] Создать систему хранения FloodWait таймеров
- [ ] Настроить TTL для различных типов данных
- [ ] Реализовать кэширование промежуточных результатов
- [ ] Протестировать запись и чтение из Redis

---

## ЭТАП 2: Интеграция с существующими сервисами

### 2.1. Интеграция с Integration Service
- [ ] Изучить API Integration Service для получения аккаунтов
- [ ] Реализовать HTTP клиент для взаимодействия с Integration Service
- [ ] Создать функции для получения:
  - [ ] Списка доступных Telegram аккаунтов пользователя
  - [ ] Статуса аккаунта (is_banned, flood_wait_until, is_working)
  - [ ] Обновления статуса использования аккаунта
- [ ] Реализовать алгоритм выбора оптимального аккаунта
- [ ] Протестировать получение аккаунтов от Integration Service

### 2.2. Интеграция с Vault (секреты и сессии)
- [ ] Настроить VaultClient с AppRole аутентификацией
- [ ] Реализовать получение Telegram .session файлов из Vault
- [ ] Создать функции для:
  - [ ] Безопасного создания временных .session файлов
  - [ ] Удаления временных файлов после использования
  - [ ] Получения api_id/api_hash из Vault
- [ ] Обновить docker-compose.yml с переменными Vault
- [ ] Протестировать получение секретов из Vault

### 2.3. Интеграция с API Gateway
- [ ] Настроить JWT аутентификацию для parsing endpoints
- [ ] Реализовать middleware для извлечения user_id из JWT токена
- [ ] Создать декораторы для проверки прав доступа
- [ ] Обновить все endpoints для работы с аутентифицированными пользователями
- [ ] Протестировать авторизацию через API Gateway

---

## ЭТАП 3: Реализация API endpoints согласно ТЗ

### 3.1. Endpoint добавления задач парсинга
- [ ] **POST /parser/queue** - основной endpoint
- [ ] Реализовать Pydantic схемы для валидации:
  - [ ] ParseTaskCreate (множественные ссылки, приоритет)
  - [ ] ParseTaskResponse (информация о созданных задачах)
- [ ] Добавить валидацию Telegram ссылок (формат t.me/username)
- [ ] Реализовать автоопределение типа (группа/канал)
- [ ] Интегрировать с очередью RabbitMQ
- [ ] Добавить проверку лимитов пользователя (по тарифному плану)
- [ ] Протестировать создание задач разных типов и приоритетов

### 3.2. Endpoints управления задачами
- [ ] **GET /parser/tasks** - список задач пользователя
- [ ] **GET /parser/tasks/{task_id}** - информация о конкретной задаче
- [ ] **POST /parser/tasks/{task_id}/pause** - поставить задачу на паузу
- [ ] **POST /parser/tasks/{task_id}/resume** - возобновить задачу
- [ ] **DELETE /parser/tasks/{task_id}** - удалить задачу
- [ ] Реализовать фильтрацию по статусу, дате, типу
- [ ] Добавить пагинацию для больших списков
- [ ] Протестировать все операции управления задачами

### 3.3. Endpoint поиска сообществ
- [ ] **GET /parser/search** - поиск по ключевым словам
- [ ] Реализовать параметры: q (query), offset, limit
- [ ] Интегрировать с Telethon для поиска публичных чатов
- [ ] Добавить фильтрацию (исключение приватных, пустых чатов)
- [ ] Реализовать пагинацию по 100 результатов
- [ ] Кэшировать результаты поиска в Redis
- [ ] Протестировать поиск по различным ключевым словам

### 3.4. Endpoint выгрузки результатов
- [ ] **GET /parser/result/{task_id}** - получение результатов
- [ ] Реализовать поддержку форматов: JSON, CSV, NDJSON
- [ ] Создать структуру данных согласно ТЗ:
  - [ ] user_id, username, full_name, status, join_date, source_link
- [ ] Добавить метаданные: дата парсинга, аккаунт, статус задачи
- [ ] Реализовать streaming для больших файлов
- [ ] Протестировать выгрузку в разных форматах

---

## ЭТАП 4: Реализация Telegram парсинга с Telethon

### 4.1. Настройка Telethon клиента
- [ ] Установить Telethon в requirements.txt (версия 1.34.0+)
- [ ] Реализовать TelegramClient wrapper с обработкой ошибок
- [ ] Настроить создание клиента из .session файла
- [ ] Реализовать управление множественными клиентами
- [ ] Добавить graceful отключение клиентов
- [ ] Протестировать подключение к Telegram API

### 4.2. Парсинг групп (iter_participants)
- [ ] Реализовать парсинг участников Telegram групп
- [ ] Извлекать данные: user_id, username, full_name, language_code, status
- [ ] Добавить получение join_date (если доступно)
- [ ] Реализовать постраничное получение участников
- [ ] Добавить обработку приватных групп
- [ ] Сохранять результаты в БД пакетами
- [ ] Протестировать на тестовых группах

### 4.3. Парсинг каналов (get_messages)
- [ ] Реализовать парсинг сообщений из каналов
- [ ] Получать комментарии к сообщениям (если включены)
- [ ] Извлекать информацию о пользователях-комментаторах
- [ ] Реализовать получение истории сообщений
- [ ] Добавить ограничение глубины (10,000 сообщений по умолчанию)
- [ ] Сохранять результаты в оптимизированном формате
- [ ] Протестировать на тестовых каналах

### 4.4. Получение общей информации о чатах
- [ ] Реализовать извлечение метаданных чата:
  - [ ] title, username, description
  - [ ] participants_count, chat_type
  - [ ] created_date, admin_rights
- [ ] Обработать различные типы чатов (супергруппы, каналы)
- [ ] Сохранять информацию в таблицу TelegramChat
- [ ] Протестировать на различных типах чатов

---

## ЭТАП 5: Обработка ошибок и лимитов Telegram

### 5.1. Обработка Telegram API ошибок
- [ ] FloodWaitError - сохранение времени ожидания в Redis
- [ ] SessionExpiredError - пометка сессии как невалидной
- [ ] AuthKeyError - обработка проблем с ключом авторизации
- [ ] ChannelPrivateError - пропуск приватных каналов
- [ ] PhoneMigrateError - обработка миграции номера
- [ ] Создать классификацию: recoverable vs fatal errors
- [ ] Протестировать обработку каждого типа ошибок

### 5.2. Rate limiting и адаптивные паузы
- [ ] Реализовать счетчик запросов (200-300 без задержки)
- [ ] Добавить адаптивную паузу после превышения лимита
- [ ] Настроить безопасный лимит: 100 сообщений/сек
- [ ] Реализовать dynamic backoff при получении FloodWait
- [ ] Добавить random jitter для избежания синхронизации
- [ ] Мониторить частоту запросов через метрики
- [ ] Протестировать работу при высокой нагрузке

### 5.3. Resume functionality (восстановление задач)
- [ ] Сохранять offset_id и message_id в Redis
- [ ] Реализовать восстановление с последней позиции
- [ ] Обновлять прогресс задачи в реальном времени
- [ ] Обрабатывать смену аккаунта с сохранением позиции
- [ ] Очистка устаревших resume points
- [ ] Протестировать восстановление после различных сбоев

---

## ЭТАП 6: Celery Worker и асинхронная обработка

### 6.1. Реализация Celery задач
- [ ] Создать основную задачу parse_telegram_chat
- [ ] Реализовать задачи для разных типов парсинга:
  - [ ] parse_telegram_group
  - [ ] parse_telegram_channel
  - [ ] search_telegram_communities
- [ ] Добавить retry логику с экспоненциальным backoff
- [ ] Настроить timeout для долго выполняющихся задач
- [ ] Протестировать выполнение задач в фоне

### 6.2. Управление аккаунтами в воркерах
- [ ] Реализовать алгоритм выбора аккаунта в задаче
- [ ] Добавить переключение аккаунтов при ban/flood
- [ ] Обновлять статус аккаунта в Integration Service
- [ ] Реализовать queue waiting при отсутствии аккаунтов  
- [ ] Добавить автоматический перезапуск задач
- [ ] Протестировать работу с множественными аккаунтами

### 6.3. Мониторинг выполнения задач
- [ ] Логировать каждый этап выполнения задачи
- [ ] Обновлять прогресс в Redis с TTL
- [ ] Сохранять статистику в БД (время выполнения, ошибки)
- [ ] Отправлять метрики в Prometheus
- [ ] Реализовать webhook уведомления (будущее)
- [ ] Протестировать мониторинг различных сценариев

---

## ЭТАП 7: Безопасность и интеграция с инфраструктурой

### 7.1. Безопасность и защита данных
- [ ] Все .session файлы только через Vault API
- [ ] Удаление временных файлов после использования
- [ ] Шифрование чувствительных данных в БД
- [ ] Валидация и санитизация всех входных данных
- [ ] Защита от injection атак
- [ ] Аудит всех действий пользователей
- [ ] Протестировать безопасность API

### 7.2. Интеграция с мониторингом
- [ ] Добавить Prometheus метрики:
  - [ ] parse_tasks_active (количество активных задач)
  - [ ] telegram_accounts_available (доступные аккаунты)
  - [ ] telegram_accounts_blocked (заблокированные)
  - [ ] flood_wait_avg (среднее время FloodWait)
  - [ ] fail_rate (процент неудачных задач)
  - [ ] resume_count (количество восстановлений)
- [ ] Настроить алерты в Alertmanager
- [ ] Создать Grafana дашборд для parsing-service
- [ ] Протестировать сбор и отображение метрик

### 7.3. Логирование и трассировка
- [ ] Настроить structured logging в JSON формате
- [ ] Добавить correlation ID для трассировки задач
- [ ] Интегрировать с ELK Stack для централизованного логирования
- [ ] Логировать все важные события и ошибки
- [ ] Добавить различные уровни логирования (DEBUG, INFO, WARN, ERROR)
- [ ] Протестировать логирование и поиск в Kibana

---

## ЭТАП 8: Тестирование и оптимизация

### 8.1. Unit тесты
- [ ] Написать тесты для всех основных функций
- [ ] Тесты для API endpoints с mock данными
- [ ] Тесты для Telegram парсинга с фиктивными клиентами
- [ ] Тесты для обработки ошибок и edge cases
- [ ] Тесты для интеграций с внешними сервисами
- [ ] Достичь покрытия кода >80%
- [ ] Настроить автоматический запуск тестов

### 8.2. Интеграционные тесты
- [ ] Тесты взаимодействия с Integration Service
- [ ] Тесты работы с Vault (получение секретов)
- [ ] Тесты полного цикла: создание задачи → парсинг → результат
- [ ] Тесты работы с RabbitMQ очередями
- [ ] Тесты сценариев с множественными аккаунтами
- [ ] Протестировать восстановление после сбоев

### 8.3. Нагрузочное тестирование
- [ ] Тестирование с 50 пользователями, 300 аккаунтами
- [ ] Тестирование 1000 задач/час согласно ТЗ
- [ ] Проверить время отклика API (<500мс)
- [ ] Тестировать стабильность при длительной работе
- [ ] Оптимизировать узкие места производительности
- [ ] Протестировать горизонтальное масштабирование

---

## ЭТАП 9: Подготовка к Proxy интеграции (будущее)

### 9.1. Архитектура proxy-adapter
- [ ] Создать абстрактный интерфейс для proxy подключения
- [ ] Реализовать заглушки для будущей интеграции
- [ ] Добавить настройки proxy на уровне:
  - [ ] Глобальные настройки (ENV переменные)
  - [ ] Настройки аккаунта в Integration Service
  - [ ] Параметры конкретной задачи
- [ ] Подготовить структуру для REST/gRPC интеграции
- [ ] Документировать интерфейс в коде

### 9.2. Подготовка к интеграции с proxy-service
- [ ] Определить API контракт с будущим proxy-service
- [ ] Создать mock proxy service для тестирования
- [ ] Реализовать fallback логику при недоступности proxy
- [ ] Добавить метрики использования proxy
- [ ] Протестировать архитектуру с mock сервисом

---

## ЭТАП 10: Деплой и production готовность

### 10.1. Подготовка к production
- [ ] Обновить docker-compose.yml для всех компонентов
- [ ] Настроить health checks для всех контейнеров
- [ ] Оптимизировать Dockerfile для production
- [ ] Настроить логротацию и управление размером логов
- [ ] Подготовить скрипты для деплоя и обновления
- [ ] Создать документацию по эксплуатации

### 10.2. Финальное тестирование
- [ ] Smoke тесты всей системы с нуля
- [ ] Тестирование интеграции со всеми сервисами
- [ ] Проверка работы мониторинга и алертов
- [ ] Тестирование backup и recovery процедур
- [ ] Валидация соответствия всем требованиям ТЗ
- [ ] Подготовка к нагрузочному тестированию на production

### 10.3. Документация и передача
- [ ] Обновить PARSING-SERVICE-PROJECT.md с финальной архитектурой
- [ ] Создать API документацию (OpenAPI/Swagger)
- [ ] Написать руководство по эксплуатации
- [ ] Подготовить troubleshooting guide
- [ ] Создать примеры использования для разработчиков
- [ ] Провести code review и документирование

---

## Дополнительные требования и ограничения

### Производительность:
- [ ] **Тестовая нагрузка**: 50 пользователей, 300 аккаунтов, 1000 задач/час ✅
- [ ] **Production нагрузка**: >1000 пользователей, >10k аккаунтов, до 10k задач/час ✅
- [ ] **Время отклика API**: <500мс при работе очереди ✅
- [ ] **Uptime**: 99.9% ✅

### Ограничения и защиты:
- [ ] **Глубина истории**: Максимум 10,000 сообщений по умолчанию ✅
- [ ] **Лимиты пользователя**: Проверка согласно тарифному плану ✅
- [ ] **Telegram лимиты**: Соблюдение всех официальных ограничений ✅
- [ ] **Классификация ошибок**: Разделение на recoverable и fatal ✅

---

> **ВАЖНО**: Каждый этап должен быть полностью завершен и протестирован перед переходом к следующему. При обнаружении критических проблем возможен возврат к предыдущим этапам для доработки.

> **Статус проекта**: 🔴 **НЕ НАЧАТ** - Требуется полная переработка существующего кода согласно данному чек-листу и техническому заданию.

---

## Критерии готовности для каждого этапа

**Этап считается завершенным только при выполнении всех условий:**
- ✅ Все пункты этапа отмечены как выполненные [x]
- ✅ Написаны и прошли unit/integration тесты
- ✅ Обновлена документация (PARSING-SERVICE-PROJECT.md)
- ✅ Проведен code review (самопроверка или партнер)
- ✅ Протестирована интеграция с зависимыми сервисами
- ✅ Зафиксированы изменения в PROJECT-STATUS.md 