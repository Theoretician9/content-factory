# <a name="header"></a><a name="content"></a><a name="x9b4f40e7ad2d1d079647ac3b945d71220c7a831"></a>Архитектура эволюционного AI-агента для Telegram (техническое задание)
## <a name="общее-описание-архитектуры"></a>1. Общее описание архитектуры
**Назначение системы:** Новый микросервис **EvolutionAI Agent** предназначен для автоматизированного ведения Telegram-канала от лица пользователя. По простой команде пользователь запускает AI-агент, который ежедневно генерирует и публикует посты, сохраняя единый стиль (персонаж канала) и сюжетную линию, и постепенно **эволюционирует стратегию контента** на основе отклика аудитории. Система интегрируется в существующую инфраструктуру (FastAPI + Celery, Redis, Vault, PostgreSQL, Docker Compose) и взаимодействует с уже работающими сервисами (Invite, Parsing, Integration), не нарушая их работу.

**Компоненты архитектуры:** Микросервис включает несколько логических модулей (агентов) и служб, объединённых оркестратором:

- **Orchestrator (Content Orchestrator):** центральный координатор, который запускает необходимые шаги для генерации контента и публикации. Он отвечает за последовательность действий, маршрутизацию данных между агентами, соблюдение SLA (ограничений времени/квот), обработку ошибок, идемпотентность выполнения и ретраи при сбоях.
- **Scheduler:** модуль расписания, управляющий выполнением задач по времени. Он планирует ежедневные задачи генерации постов (на каждый **слот** контент-плана), еженедельные задачи оптимизации стратегии и ежемесячные задачи ревизии стратегии. Scheduler реализован с помощью Celery Beat (либо APScheduler) для периодического запуска задач.
- **Policy Router (Model Policy Router):** компонент, определяющий какие модели ИИ использовать на каждом этапе, исходя из сложности задачи и бюджета. Он применяет политику эскалации: сначала попытка с локальной моделью, и переход на API-модель только если требуется более высокое качество или приоритет контента высокий.
- **Агенты контента:** набор подкомпонентов, каждый из которых выполняет отдельную роль в конвейере контент-создания. К ним относятся: Prompt Generator, Research Agent, Insight & Analysis Agent, Writer, Style Adapter, Art Director, Publisher, Optimizer, Telemetry/Feedback, Memory Manager (подробности – в разделе 2).
- **Хранилища и интеграции:** система использует несколько хранилищ данных и внешних API. Основная база – PostgreSQL (хранит стратегии, расписание, тексты постов, метрики и пр.), дополнена векторным хранилищем (Qdrant или Weaviate) для семантического поиска/памяти, хранилищем файлов (MinIO/S3 для медиа-ресурсов), кешем Redis (для очередей, локов, временного scratchpad), а также сервисами внешней интеграции: Telegram Integration Service для взаимодействия с Telegram, Parsing Service для получения данных из Telegram и веб-источников, Invite Service для управления аудиторией, Search API/Browser для веб-ресёрча, и Stocks/Image генераторы для работы с изображениями.

**Режимы работы:** Агент поддерживает несколько режимов в разных временных масштабах: - **Ежедневный цикл:** Каждый день (или несколько раз в день, согласно контент-плану) Orchestrator запускает **дневной слот** – полный конвейер от сбора свежей информации до публикации поста. Посты создаются по принципу «день-в-день»: всегда на основе актуальных данных за последние сутки-двое, чтобы контент был свежим. Агент соблюдает единый голос канала (persona) и поддерживает непрерывную сюжетную нить между постами. - **Еженедельная эволюция стратегии:** Раз в неделю агент проводит лёгкую корректировку стратегии. На основе собранных за неделю метрик (ER – engagement rate, CTR, сохранения и др.) Optimizer пересматривает **веса рубрик и слотов** (какие темы и форматы лучше заходят аудитории), немного изменяет промпты для Writer/Research (например, «утренние посты делать короче, добавлять больше фактов») и может перестроить контент-план (Calendar) на ближайшие недели, не нарушая общую сюжетную линию. - **Ежемесячная ревизия стратегии:** Раз в месяц выполняется глубокая эволюция стратегии. Генерируется новая версия стратегии (vN+1) на основе анализа всех накопленных постов и трендов рынка. При этом **ядро стратегии** сохраняется (персонаж, тональность, ключевые «контент-столпы» канала), а гибкая часть обновляется – добавляются новые рубрики или углы подачи, исключаются неэффективные темы, учитываются новые тренды. После обновления стратегии агент автоматически пересобирает календарный план постов на следующие 4 недели вперёд с учётом новой стратегии.

Архитектура построена так, чтобы агент работал автономно, но при этом поддавался мониторингу и тонкой настройке. Ниже описаны роли каждого компонента и их взаимодействие.
## <a name="x2b6145a70d6b26680527770e291a94747faf35a"></a>2. Назначение каждого агента и используемые модели
Каждый агент в системе отвечает за определённую функцию в цепочке генерации и эволюции контента. Ниже перечислены основные агенты, их задачи, а также используемые ML-модели (локальные или API) и условия применения моделей:

- **Prompt Generator (Prompt Engineer):** отвечает за формирование и версионирование системных и пользовательских промптов для различных этапов. Он хранит шаблоны промптов для каждой роли (персона/стиль, генерация текста, ресёрч, оптимизация и др.) и подставляет актуальные параметры (например, выдержки из стратегии, указания по тону, ограничения) перед вызовом моделей. **Модели:** сам по себе Prompt Generator не использует ML, но формирует подсказки для последующих агентов. Обновление промптов происходит версионно – при каждой эволюции стратегии (еженедельно/ежемесячно) могут вноситься правки в тексты инструкций для Writer, Research и др.
- **Research Agent:** выполняет поиск актуальной информации перед созданием каждого поста. Он **собирает свежие сигналы** из внешних источников:
- *Telegram (через Parsing Service):* ищет по тематическим каналам последние посты и обсуждения (например, за последние 48–72 часа) по теме текущего слота. Для этого используется API Parsing Service – например, endpoints GET /tg/search (поиск каналов по ключевым словам, с фильтрацией наличия обсуждений) и GET /tg/fresh (получение новых сообщений/комментариев по заданной теме или списку каналов).
- *Web (через Search API и браузер):* выполняет веб-поиск свежих статей, новостей, кейсов по теме слота. Может использовать API поиска (Brave, Bing, SerpApi) либо headless-браузер (Playwright) для парсинга содержимого страниц. Собранная информация нормализуется: извлекаются заголовки, лиды, основной текст, дата публикации, URL.
- **Модели:** сам сбор информации – без использования LLM (опирается на внешние API). Однако для предварительной фильтрации или кластеризации результатов Research Agent может использовать embeddings (например, моделями **bge-m3** или **e5-large-v2**) чтобы отбросить дубликаты и оставить наиболее релевантные и разнообразные источники. Если результатов мало или источник недоступен, агент применяет политику fallback: берёт данные из внутреннего корпуса (например, сохранённые статьи за последние ~14 дней) и помечает, что свежих данных нет.
- **Insight & Analysis Agent:** на основе сырых данных от Research Agent извлекает ключевые инсайты. Он агрегирует информацию из разных источников (телеграм-посты, статьи, комментарии) и формирует **3–7 тезисов** – факты, цифры, цитаты, противоречивые мнения – которые станут основанием для поста. Также агент оценивает **новизну** каждого тезиса (насколько недавно появилась информация, насколько редко упоминается в нашем канале) и отмечает источник.
- **Модели:** Insight Agent использует локальные модели для суммаризации и извлечения фактов. Например, он может применять средние локальные LLM (типа **LLaMA-3B/7B** или **Mistral-7B**) или их увеличенные версии (Mixtral ensemble ~8×7B) при наличии GPU для обработки большого текста. Эти модели берут консолидированный текст источников (или заранее полученные эмбеддинги) и генерируют список важных тезисов. Для ранжирования новизны может применяться просто логика дат или семантическое сравнение с ранее сохраненными инсайтами (через векторное хранилище). Insight Agent работает локально, так как объем данных предсказуем, и требует оперативности. API-модели здесь не применяются, чтобы не тратить бюджет.
- **Writer Agent:** генерирует текст поста на основе инсайтов и контекста стратегии. Этот агент работает в два этапа:
- **Draft (черновик):** создаёт первоначальный вариант поста. В него включаются 3–5 абзацев, основанных на предоставленных инсайтах, с связным повествованием. Writer учитывает контекст персонажа и рубрику слота (например, рубрика «кейсы», «новости», «гайд» – форматы могут отличаться стилем). **Модели (локально):** Для черновика по умолчанию используется локальная LLM среднего размера – например, **Llama-2 13B** или **Mistral-7B** (если ресурсов мало) либо более крупная модель на собственном GPU (до 30–70B параметров, если доступно). Локальная модель справляется с первичным генеративным заданием без затрат денег, но с возможными огрехами в тексте.
- **Polish (финальная доработка):** улучшает черновик до финального текста. Добавляются завершающие штрихи: проверка связности, улучшение формулировок, добавление призыва к действию (CTA) или вопроса в конце поста, расстановка хэштегов. **Модели (API по необходимости):** Этот этап может использовать платную модель с высоким качеством (например, **GPT-4** или аналог Anthropic Claude) – особенно для важных постов. Политика такая: если слот помечен как **high\_priority** (например, ключевой еженедельный пост) **или** если локальный черновик имеет признаки низкого качества (выявлено эвристиками), Orchestrator через Policy Router направит черновик в API-модель для доводки. Иначе используется локальная модель или модель меньшего API (например, **GPT-4 mini** либо **Claude Instant** для быстрого анализа) для экономии. В результате получается отредактированный финальный текст поста.
- **Style Adapter (Voice & Style Agent):** отвечает за приведение текста поста к единому стилю и тональности, соответствующим персоне канала. Он реализует **“persona canon”** – набор неизменных элементов стиля: предпочитаемая лексика, тип повествования (1-е лицо/3-е лицо, официальность или разговорный тон), скорость/ритм подачи, отношение к эмодзи и форматированию, запрещенные фразы. Style Adapter применяет эти правила к финальному тексту:
- Исправляет тональные несоответствия, разбивает длинные абзацы если стиль предусматривает лаконичность, либо объединяет если нужна цельность.
- Добавляет или удаляет эмодзи согласно политике (например, “не более 1 эмодзи в посте” или “использовать эмодзи для маркеров в списках”).
- Заменяет слова, которые персона никогда не употребляет, на допустимые синонимы (список табу-слов хранится в **Memory**).
- **Модели:** Style Adapter в основном работает правилом на основе сохраненных шаблонов и возможно небольшой локальной модели для перефразирования отдельных предложений (например, тот же Mistral-7B для переформулировки). Он **не** использует дорогие API, т.к. задача стилизации локальна и ограничена по объему. Также сюда встроен **лингвистический линтер** – проверка орфографии, грамматики, соответствия длины поста требуемому диапазону, наличия всех необходимых ссылок или хэштегов.
- **Art Director (Image Generator):** подбирает визуальное сопровождение поста. Для каждого поста формируется **бриф на изображение** (на основе темы поста и его настроения), после чего Art Director пытается найти подходящее изображение:
- Сначала агент ищет **стоковое фото** через API стоковых сервисов (Unsplash, Pexels и т.д.) по ключевым словам. Если находятся изображения, они оцениваются моделью (например, CLIP или эстетическим классификатором) на соответствие теме и общей эстетике канала. Выбирается лучшее.
- Если подходящего стокового изображения нет, агент может сгенерировать картинку с помощью модели генерации изображений (например, Stable Diffusion XL, DALL·E 3 или другой, если подключено). Сгенерированные варианты также оцениваются и выбирается наилучший.
- **Модели:** Поиск стоков – через API (без ML). Генерация – через подключенную модель (локально или внешняя API, в зависимости от настроек). Оценка изображений – с помощью локальной модели CLIP либо специализированного классификатора качества, чтобы выбрать наиболее релевантное изображение. Art Director может быть отключен на этапе MVP, но предусмотрен архитектурно.
- **Publisher:** занимается непосредственным **публикационным процессом** в Telegram. Он получает от Orchestrator готовый контент: финальный текст поста, медиавложения (картинки) и метаданные (например, время публикации). Функции Publisher:
- Отправить пост на предпросмотр (например, в приватный сервисный чат Telegram, куда подключены редакторы или сам пользователь, для последней проверки).
- Запланировать отложенную публикацию поста в канал на указанное время слота (если пост не для немедленного выхода). Использует возможности Telegram API для отложенных сообщений, либо самостоятельно следит за временем.
- Опубликовать контент в канал. Для взаимодействия с Telegram используется существующий **Integration Service** – Publisher передаёт ему контент и идентификатор сессии/канала. Integration Service уже управляет авторизацией (сессии Telegram хранятся в Vault), обработкой двухфакторной авторизации, и возвращает результат отправки.
- Добавлять к посту интерактивные элементы, если нужно: например, кнопки URL с UTM-метками, ссылки на опросы или треды обсуждения.
- **Модели:** не применяются. Publisher – интеграционный модуль, работает через Telegram API (Telethon/Pyrogram) косвенно, ошибок AI тут нет. Он должен учитывать ограничения Telegram (например, **Flood Wait** – паузы между публикациями): при превышении лимитов делает задержку или сообщает Orchestrator об ошибке.
- **Telemetry & Feedback Agent:** собирает статистику и отзывы после публикации. Его задачи:
- **Метрики поста:** через 1 час, 24 часа и 7 дней после публикации поста собрать основные показатели – число просмотров, реакции (лайки/emoji реакции), количество репостов, сохранений (если есть), CTR (если в посте была ссылка). Эти данные Parsing Service может предоставить, либо Integration Service (если он умеет читать стат кнопку). Полученные метрики сохраняются в базу.
- **Комментарии:** если в канале открыты комментарии (через связанный чат), агент парсит комментарии к посту (с использованием Parsing Service, который может возвращать список комментариев). Он сохраняет текст комментариев, автора, время. Дополнительно проводится **анализ тональности** комментариев (sentiment analysis) и выделение ключевых тем обсуждения. Для тональности можно использовать лёгкую модель (локальный классификатор, например Naive Bayes по тонально размеченному корпусу или маленькую LLM). Ключевые темы – через извлечение топ-слов или embeddings + кластеризация.
- **Модели:** sentiment-анализ и тематическая классификация могут быть реализованы простой NLP-моделью или правилами. Например, локальный **токсичность-классификатор** для модерации/тональности, embeddings для кластеризации тем комментариев. Ничего дорогого: все делается локально и регулярно.
- **Optimizer:** на основе телеметрии оптимизирует стратегию контента. Он действует в двух режимах:
- **Weekly update:** раз в неделю собирает агрегированные метрики по рубрикам и форматам: какие типы постов получили больший отклик (ER, CTR, сохранения). На основе этого Optimizer корректирует **веса рубрик и слотов**. Практически это может быть реализовано через алгоритм **многорукого бандита**: рубрикам, давшим лучший результат, повышаем вероятность появления в календаре, неуспешным – понижаем. Также Optimizer может выдавать небольшие “дельты” для промптов Writer/Research – например, указывает уменьшить длину утренних постов или добавлять больше фактов, если замечен спрос на фактаж. После этого Optimizer вызывает обновление календаря: перетасовывает темы/рубрики в сетке слотов на ближайшие недели в рамках текущей версии стратегии (не меняя глобальную идею).
- **Monthly review:** раз в месяц Optimizer (совместно со Strategy Agent, если вычленять) проводит глубокий анализ: берет историю всех постов за месяц, их метрики, а также собирает **внешние тренды** (например, какие новые темы появились у конкурентов или в новостях – можно повторно задействовать Research Agent для общей темы канала). Далее с помощью мощной модели формируется обновлённая стратегия канала. **Модели:** для еженедельной оптимизации модель не нужна – это алгебра и простые формулы или легковесная ML (бандит или регрессия). Для ежемесячной ревизии может привлекаться **сильная LLM** через API (GPT-4 или будущие GPT-5) для анализа больших объемов текста и формулирования новой стратегии в виде текста (обновленные pillars, новые подходы). Это разовое в месяц, поэтому оправдано использовать платную модель высокого качества. Optimizer затем сохраняет новую стратегию (версия vN+1) в базу и инициирует пересборку календаря на следующий месяц, учитывая новую стратегию.
- Optimizer также отвечает за передачу **дельт промптов**: он может обновлять записи в таблице prompts (например, версию промпта Writer увеличивает и изменяет текст, добавляя инструкцию «короче и более фактически» для утренних постов).
- **Memory Manager:** обеспечивает долговременную память и контекст для агента. Он хранит:
- **Persona Canon:** описание персоны канала (стиль, табу, формат общения) – используется во всех релевантных промптах и никогда сильно не меняется.
- **Content Pillars:** список ключевых тем/рубрик канала.
- **Used Hooks Registry:** реестр использованных ранее “крючков” – оригинальных приемов начала поста, историй, примеров. Это нужно, чтобы не повторять один и тот же заход дважды. При генерации нового контента Memory Manager помечает, какие hook уже были, но может предложить **вариации** вместо прямого повтора.
- **Continuity Summaries:** краткие конспекты прошлых постов, особенно в рамках одной рубрики или сюжетной линии. Перед созданием поста Memory Manager может предоставить Writer’у сводку предыдущего связанного поста, чтобы обеспечить преемственность (например, если неделю назад был пост “Часть 1”, то напомнить основные пункты для “Часть 2”).
- **Long-term content embeddings:** векторный индекс всех прошлых материалов канала, чтобы можно было быстро искать, упоминался ли уже определённый факт или тема, и избежать дублирования или, наоборот, сослаться на старый пост. Векторное хранилище (Qdrant/Weaviate) используется здесь: при подготовке нового поста можно сделать семантический поиск похожего контента в архиве канала.
- **Модели:** Memory Manager сам по себе – это обертка над хранилищами (Postgres для текстовых артефактов, Qdrant для эмбеддингов). Он использует модели косвенно: для обновления эмбеддингов контента (например, при сохранении нового поста рассчитывает embedding через модель вроде **e5-large-v2**), для сравнения новых тезисов с прошлыми (чтобы пометить новизну инсайта) и пр. Все операции происходят асинхронно и не блокируют основной pipeline.

Каждый агент интегрирован в общую цепочку, координируемую Orchestrator’ом, и обмен данными между ними происходит либо через прямые вызовы (внутри одного процесса), либо через события/очереди (если выносить агента в отдельный сервис). На этапе реализации MVP (минимально жизнеспособного продукта) допускается объединить большинство агентов внутри одного микросервиса для упрощения, с вызовами функций напрямую, а в будущем их можно вынести в отдельные сервисы и коммуникацию через API или RabbitMQ события.
## <a name="интеграция-с-внешними-сервисами"></a>3. Интеграция с внешними сервисами
Для полноценной работы AI-агента требуется тесная интеграция с существующими сервисами и внешними API:

- **Telegram Integration Service:** вместо прямого обращения к Telegram Bot API или клиенту, агент пользуется существующим Integration Service. Этот сервис уже отвечает за авторизацию в Telegram (включая хранение session-файлов, работу с 2FA, которые хранятся в Vault), предоставляет подключение к каналам. Publisher обращается к Integration Service для публикации сообщений: например, вызывается метод publish\_message(channel\_id, text, media, schedule\_time) или соответствующий REST endpoint Integration-сервиса. Integration Service берёт на себя отправку в Telegram через Telethon/Pyrogram и возвращает результат (успех/ошибка). Также Telemetry Agent может использовать Integration Service (или Parsing Service) для чтения метрик поста – например, если Integration умеет получать количество просмотров/реакций (хотя чаще эти данные берутся из Parsing Service).
- **Parsing Service:** этот сервис уже реализует сбор данных из Telegram (поиск каналов, парсинг их постов и комментариев). EvolutionAI Agent расширяет его использование:
- Research Agent через Parsing Service делает поиск по каналам: GET /tg/search?query=... может вернуть список популярных каналов или последних сообщений по теме.
- Также Parsing Service может предоставлять интерфейс GET /tg/fresh?topic=X&hours=72 – список сообщений и комментов из Telegram за последние 72 часа, связанных с темой X (например, по хештегам или ключевым словам). Используя такой API, агент получает “сырой материал” из соцсети для аналитики.
- Parsing Service также применим для получения комментариев к нашим собственным постам: Telemetry Agent может вызывать, например, GET /tg/comments?post\_id=... чтобы получить все комментарии.
- **Взаимодействие:** через HTTP API (REST) или, при большой нагрузке, через очереди RabbitMQ (событие запроса на парсинг и событие с результатом). На старте достаточно REST. Важно: Parsing Service – ядро компонента Research-TG в нашей системе.
- **Invite Service:** сервис управления инвайтами и аудиторией. Хотя он не участвует напрямую в создании контента, интеграция с ним позволяет агенту учитывать рост аудитории или нацеливать контент. Например:
- После публикации поста с CTA “поделитесь с друзьями” можно вызвать Invite Service, чтобы сгенерировать новые приглашения или отслеживать, сколько человек пришло.
- Invite Service может предоставлять демографические данные или активность приглашенных пользователей. Эти данные могут учитываться Optimizer’ом при стратегии (но это опционально).
- В рамках данного задания прямых вызовов Invite Service может не быть, но архитектура закладывает возможность взаимодействия (через API или общую БД). Например, если определённый пост предназначен для увеличения количества подписчиков, агент может запросить у Invite Service актуальную ссылку-приглашение и добавить её в пост.
- **Web Search API / Browser:** для веб-ресёрча агент использует внешние поисковые сервисы:
- Может быть интегрирован SerpAPI, API Brave Search или Bing Web Search API. Эти сервисы требуют API-ключи (они хранятся в Vault и подтягиваются в конфигурацию).
- Alternatively, для более гибкого парсинга страниц используется headless-браузер (Playwright) в сочетании с поисковиками: сначала выполняется поиск, затем автоматически открываются топ-N результатов и извлекается текст. Этот процесс тяжёлый, поэтому ограничивается 10-20 результатами и кэшируется (чтобы не дергать одни и те же запросы часто).
- Интеграция реализована как отдельный модуль или сервис **Research-Web**. Он предоставляет endpoint, например GET /web/fresh?topic=X&hours=72&limit=20, который возвращает JSON списка свежих статей по теме X: заголовок, краткий lead, URL, время публикации, очищенный текст (можно укоротить до пары абзацев). EvolutionAI Agent вызывает этот сервис для внешних данных. В случае, если прямое соединение из контейнера с Интернетом недоступно, можно проксировать через существующие возможности (в рамках Docker/K8s настроить доступ или через сервис-агент).
- **Stocks & Media Services:** интеграция для получения изображений:
- Используются публичные API стоковых фото: Unsplash, Pexels, Pixabay – у каждого есть API с поиском по ключевым словам. Нужны API ключи (хранятся в Vault).
- Запрос формируется Art Director’ом, например GET https://api.pexels.com/v1/search?query=<keywords>&per\_page=5.
- Полученные URL изображений сохраняются (в MinIO/S3, если нужен кэш). Если изображения требуют кредит авторства, агент может либо отфильтровать такие, либо учитывать это (в пост, вероятно, не нужно, т.к. телеграм это не отображает).
- **Генерация изображений:** если задействована, интеграция с моделью Stable Diffusion или DALL·E. В рамках microservice можно вызывать отдельный сервис, где развёрнута SDXL модель, или внешнее API (например, OpenAI DALL·E API). Ключи и URL хранятся в Vault.
- **Хранилище медиа:** MinIO либо S3 buckets используются для хранения сгенерированных изображений и, возможно, сохранения уже использованных стоковых, чтобы не терять их (и на случай повторной отправки). Publisher получает либо URL до файла, либо сам файл (например, путь в общем volume или ссылку на объект S3) для загрузки в Telegram.
- **Vault (Hashicorp Vault):** все чувствительные данные хранятся в Vault, и микросервис EvolutionAI Agent имеет доступ через опцию **AppRole** (каждый сервис – свой role\_id/secret\_id). При запуске сервис логинится в Vault и получает нужные секреты:
- Telegram session / API токены (возможно, Integration Service сам использует Vault, но EvolutionAI может получать, например, ID сессии или токены для Parcing Service если требуются).
- API keys для внешних сервисов: ключи поисковых API, ключи стоковых сервисов, ключ OpenAI/Anthropic для использования GPT-4/Claude.
- DB credentials, JWT секрет для подписи токенов – тоже все из Vault, чтобы не хранить в .env.
- **Безопасность:** Все вызовы к Vault ограничены ролями, никакие секреты не закодированы в коде. В случае потери соединения с Vault сервис может работать с ранее загруженными ключами в памяти, но при перезапуске требует Vault.
- **Existing Project Integration:** новый микросервис развёртывается через Docker Compose в составе проекта, общаясь с остальными через сети Docker. Он регистрируется в сервис-дискавери/оркестраторе (если используется). При необходимости на уровне оркестрации (K8s) выставляются переменные окружения: адреса Redis, PostgreSQL, Vault, креды RabbitMQ и т.д., уже существующие в проекте. Сервис не должен нарушать существующий функционал Invite/Parsing/Integration, а дополняет его. Например, Orchestrator может вызывать API Parsing и Integration, но не напрямую лезет в их базы.

В результате, EvolutionAI Agent acts как **“умный контент-контур”** поверх существующих сервисов: он берёт лучшие данные от Parsing и внешних API, использует ML для генерации текста/изображений, а затем через Integration Service размещает контент, замыкая цикл обратной связи через Parsing Service (метрики/комменты).
## <a name="базы-данных-и-схемы"></a>4. Базы данных и схемы
Микросервис использует PostgreSQL (общий или отдельный схему) для хранения большинства данных, а также дополнительное векторное хранилище и кеши. Ниже приведены основные таблицы и данные:

- **strategies** – хранение стратегий контента (различных версий) для каждого Telegram-канала.
- id (UUID, первичный ключ)
- channel\_id (INTEGER/BigInt, идентификатор канала или внешний ключ на сущность канала, если такая есть в системе)
- version (INTEGER, номер версии стратегии, начиная с 1)
- created\_at (TIMESTAMPTZ, время создания версии)
- persona\_md (TEXT, описание персоны и голоса канала, в markdown)
- pillars (JSONB, массив или объект с перечнем основных контент-пилларов – ключевых тем)
- anti\_topics (JSONB, список запрещённых тем/сюжетов, которых следует избегать)
- tone\_guide\_md (TEXT, текстовые указания по тону и стилю, напр. “общаться на ты, избегать жаргона”)
- goals (JSONB, целевые метрики и задачи стратегии – например, “увеличить вовлечённость на X%”)
- weights (JSONB, веса/приоритеты рубрик и типов постов при данной стратегии – например, формат “гайд” 30%, “новости” 20% и т.д.)
- **calendar\_slots** – календарный план постов (слоты контент-плана).
- id (UUID, первичный ключ слота)
- channel\_id (IDENTIFIER канала, для связи со стратегией)
- strategy\_version (INTEGER, версия стратегии, на основе которой создан слот; foreign key -> strategies.version, через channel\_id связь)
- dt (TIMESTAMPTZ, запланированная дата и время публикации в этом слоте)
- pillar (TEXT, тема/рубрика поста в этом слоте, соответствующая одному из pillars стратегии)
- format (TEXT, формат поста – например, “story”, “case”, “news”, “guide” – определяет шаблон подачи)
- ab\_flag (TEXT или BOOLEAN, флаг для A/B тестирования контента если используется; например, ‘A’ или ‘B’ версия поста)
- status (TEXT, статус слота: draft – сгенерирован черновик, scheduled – запланирован к публикации, posted – успешно опубликован, skipped – пропущен)
- **insights\_daily** – (может называться просто insights) таблица, хранящая извлечённые инсайты для каждого слота/дня. Каждый запуск Research+Analysis сохраняет сюда результаты.
- id (UUID, первичный ключ записи инсайтов)
- slot\_id (UUID, foreign key -> calendar\_slots.id, слот, для которого собраны инсайты)
- fetched\_at (TIMESTAMPTZ, время сбора информации)
- sources (JSONB, список источников, использованных для инсайтов, например идентификаторы статей и постов)
- facts\_md (TEXT, сводный текст или markdown, включающий все тезисы/факты, на базе которых писался пост)
- quotes (JSONB, список цитат или высказываний с указанием источника, если выделялись)
- freshness\_score (INTEGER или FLOAT, оценка актуальности данных, напр. по времени: чем новее источники, тем выше)
- urls (JSONB, массив URL оригинальных материалов, чтобы при необходимости в посте дать ссылки)
- **posts** – таблица созданных постов (черновиков и опубликованных).
- id (UUID, первичный ключ поста)
- slot\_id (UUID, внешний ключ на слот календаря, для которого пост создан)
- title (TEXT, заголовок поста, если предусмотрены заголовки; часто в Telegram-каналах посты без отдельного заголовка, тогда можно не заполнять)
- text\_md (TEXT, полный текст поста в markdown/HTML-разметке, уже финальный или черновой)
- assets (JSONB, список медиа-ресурсов, прикрепленных к посту – ссылки на изображения, видео и т.д.)
- checks (JSONB, результаты проверок качества: например, {spellcheck: 0 ошибок, sentiment: ‘neutral’, plagiarism: 5%} )
- plagiarism\_score (FLOAT, процент заимствований/повторов, выявленный анти-плагиатом)
- status (TEXT, статус поста: draft – черновик готов, review – отправлен на предпросмотр, scheduled – в очередь на отправку, posted – опубликован, error – ошибка при публикации)
- **metrics** – метрики отклика для постов. Хранит показатели через определённые интервалы времени.
- post\_id (UUID, внешний ключ на пост)
- views\_1h, views\_24h, views\_7d (INTEGER, число просмотров через 1 час, 24 часа и 7 дней после публикации)
- reactions (INTEGER, количество реакций (emoji-лайков) суммарно)
- forwards (INTEGER, сколько раз пост переслали/репостнули)
- saves (INTEGER, сколько раз сохранили/добавили в избранное)
- ctr (FLOAT, click-through rate, если пост содержал ссылку; иначе 0 или NULL)
- collected\_at (TIMESTAMPTZ, время последнего обновления метрик – например, после 7 дней)

*Примечание:* Метрики можно хранить как одной строкой с фиксированными полями (как указано выше), обновляя её по мере поступления данных (через 1h, 24h, 7d), либо как несколько записей (например, отдельная таблица metrics\_log с полем window = [1h/24h/7d]). Для простоты используем фиксированные колонки для ключевых точек.

- **comments\_index** – индекс комментариев к постам канала (если комментарии доступны).
- post\_id (UUID, внешний ключ на пост)
- comment\_id (TEXT или BIGINT, идентификатор комментария в Telegram, уникальный)
- ts (TIMESTAMPTZ, время комментария)
- author (TEXT, имя/идентификатор автора комментария)
- text (TEXT, содержимое комментария)
- sentiment (TEXT, оценка тональности комментария, например ‘positive’, ‘negative’, ‘neutral’)
- topics (JSONB, ключевые темы или упоминаемые сущности в комментарии, список тегов)
- **prompts** – библиотека промптов, используемых агентом, с версионированием.
- id (UUID, первичный ключ промпта)
- role (TEXT, роль/назначение промпта, например: writer, research, style, persona, optimizer)
- version (INTEGER, версия данного промпта)
- body\_md (TEXT, текст шаблона промпта в markdown, содержащий инструкции для LLM)
- changelog (TEXT, описание изменений при обновлении версии промпта)
- created\_at (TIMESTAMPTZ, время создания/обновления данной версии)

Отношения между таблицами: одна стратегия (strategies) ко многим слотам (calendar\_slots) по channel\_id и версии; один слот к одному посту (posts); один пост к одной записи метрик (metrics) и ко многим комментариям (comments\_index). Таблица prompts глобальна или на уровне канала (можно добавлять поле channel\_id, если нужны персональные промпты, но базово – общие шаблоны).

**Векторное хранилище:** внедряется, например, Qdrant или Weaviate, для хранения эмбеддингов: - **content\_index:** каждый пост (или даже каждый тезис инсайта) может сохраняться как вектор. Это нужно для: - Поиска похожего контента (чтобы не повторяться либо чтобы создать связи между постами). - Антиплагиата: при подготовке нового поста можно сравнить его вектор с базой внешних текстов (например, сохранённых статей из Research или содержимого других каналов) – близкие соседи могут указать на возможный плагиат. - Долговременной памяти: быстрый поиск по смыслу по архиву канала. - **embeddings for external sources:** опционально, внешние статьи из веба или лучшие посты конкурентов тоже можно складывать в векторное хранилище, помечая дату. Optimizer ежемесячно может доставать топ-новости месяца по похожести к нашим темам.

Каждая запись в векторном индексе хранит: id, embedding (VECTOR), метаданные (тип контента, дата, ссылка на исходник). Qdrant/Weaviate предоставляет API для добавления и поиска; EvolutionAI Agent будет вызывать их при инсайтах и проверке новизны.

**Кеш и Scratchpad:** Redis используется для нескольких целей: - **Broker/Queue:** Если Celery настроен на Redis (вместо RabbitMQ), то задачи идут через него. Redis также хранит результаты задач, если необходимо. - **Locks и Idempotency:** Orchestrator ставит ключ в Redis (например, task\_lock:{channel\_id}:{slot\_dt}) при запуске генерации поста, чтобы два раза не запустился один и тот же слот. Этот же ключ может использоваться как контроль идемпотентности: если задача уже выполнялась, повторный запрос на тот же слот игнорируется или возвращает существующий результат. - **Scratchpad:** временное хранилище данных между стадиями, если нужно разделить обработку. Например, Research Agent может положить сырые источники во временный ключ (research:{slot\_id}:sources), чтобы Insight Agent их оттуда взял. Хотя чаще агенты передают данные в памяти, но на случай распределённых воркеров Redis помогает шарить состояние. - **Caching:** Redis может кешировать результаты внешних запросов (например, результаты веб-поиска по определённому запросу на несколько часов, чтобы при схожих запросах не дергать API). Также можно кешировать сгенерированные изображения или эмбеддинги страниц, чтобы не пересчитывать. - **Rate limiting:** Кроме того, Redis удобно использовать для подсчёта запросов к внешним API (token bucket для Search API, ограничение на частоту публикаций в Telegram и пр.). Например, для Telegram publishing – держать счетчик сообщений в минуту/час и вводить задержки, если нужно, реализуя глобальные лимиты.

Все новые таблицы и индексы будут созданы миграциями (но миграционные файлы тут не приводим). Необходимо добавить индексы на ключевых полях: например, calendar\_slots(channel\_id, dt), posts(slot\_id), metrics(post\_id), comments\_index(post\_id). Внешние ключи обеспечивают целостность (например, удаление стратегии может каскадно пометить связанные слоты как архивные). TimescaleDB можно использовать для таблицы метрик (чтобы удобно хранить временные ряды просмотров), но в минимальной схеме достаточно и обычных полей.
## <a name="api-эндпоинты-и-примеры"></a>5. API эндпоинты и примеры
Микросервис предоставляет REST API для управления стратегиями и контентом. Все endpoints требуют авторизации по JWT. JWT токен выдаётся внешней Auth-системой (предположительно, уже имеющейся в проекте) и должен содержать информацию о пользователе и, возможно, о доступных ему каналах. Секрет для проверки JWT (или публичный ключ) загружается из Vault при старте сервиса.

Основные эндпоинты (**base path** условно считаем /api/evo для данного сервиса):

- **Стратегии (Strategy):**
- GET /strategies – получить список стратегий (активных и прошлых) доступных каналов пользователя. Может поддерживать фильтр по channel\_id.
- GET /strategies/{strategy\_id} – подробности конкретной стратегии (включая поля persona, pillars, weights и т.д.).
- GET /strategies/{channel\_id}/active – получить активную стратегию для канала (последнюю версию).
- POST /strategies – создать новую стратегию. **Пример запроса:** пользователь указывает параметры для стратегии v1 своего канала:

  {\
  `  `"channel\_id": 123456,\
  `  `"persona": "Экспертный тон, от первого лица...",\
  `  `"pillars": ["Продажи", "Маркетинг", "Lifehack"],\
  `  `"anti\_topics": ["Политика", "Спорт"],\
  `  `"tone\_guide": "Общаться на ты, избегать канцелярита...",\
  `  `"goals": {"ER\_target": 15.0, "subscribers\_target": 10000}\
  }

  Сервис создаёт запись в strategies с version=1, и генерирует базовый контент-план (слоты) на несколько недель вперёд. **Пример ответа:**

  {\
  `  `"strategy\_id": "uuid-strategy-1",\
  `  `"channel\_id": 123456,\
  `  `"version": 1,\
  `  `"created\_at": "2025-09-05T12:00:00Z",\
  `  `"status": "active",\
  `  `"next\_slots": 28  // кол-во слотов вперед сгенерировано\
  }
- PUT /strategies/{strategy\_id} – вручную обновить существующую стратегию (например, подправить persona или goals). Обычно стратегии обновляются Optimizer’ом автоматически, но этот endpoint позволяет администратору внести коррективы. Если вносятся значимые изменения, версия может повышаться.
- POST /strategies/{strategy\_id}/activate – (опционально) переключить стратегию канала на данную версию (если, например, была подготовлена новая версия v2, но не применена, этим запросом можно сделать её активной и начать публиковать по ней).
- **Контент-план и расписание (Calendar):**
- GET /calendar/{channel\_id}/slots?from=YYYY-MM-DD&to=YYYY-MM-DD – получить слоты запланированных постов канала за заданный период. Возвращает список слотов с полями: дата/время, тема, статус.
- POST /calendar/slots – добавить новый слот (например, если хотят вручную вставить внеплановый пост).
- PUT /calendar/slots/{slot\_id} – обновить слот (сменить время или тему, если статус еще draft).
- POST /calendar/reflow – перераспределить оставшиеся слоты календаря с учётом актуальных весов и стратегии. Это вызывается Optimizer’ом автоматически еженедельно, но доступно и вручную. Запрос может содержать channel\_id и опционально список корректировок (например, “увеличить частоту постов рубрики X до 2 в неделю”). Сервис перечитывает текущую стратегию и метрики, обновляет записи calendar\_slots (может изменить pillar некоторых будущих дат, добавить или удалить слоты, чтобы соответствовать новой стратегии).
- **Посты (Posts) и генерация контента:**
- GET /posts?channel\_id=...&status=draft – получить список сгенерированных черновиков (не опубликованных) для канала. Это позволяет просматривать и вручную редактировать тексты до публикации, если нужно.
- GET /posts/{post\_id} – получить подробности поста (включая текст, метаданные, статус).
- POST /posts/generate – сгенерировать пост (черновик) для ближайшего свободного слота или на заданную тему.
  - **Тело запроса:** может быть либо пустым (что означает “возьми ближайший по времени слот в календаре и сгенерируй пост для него”), либо содержать параметры:

    {\
    `  `"channel\_id": 123456,\
    `  `"slot\_id": "uuid-slot-789",   // опционально: конкретный слот\
    `  `"topic\_override": "Заданная тема", // опционально: сгенерировать на свою тему вне календаря\
    `  `"high\_priority": false        // флаг приоритета (влияет на модель polisher)\
    }
  - **Логика:** Если указан slot\_id, система генерирует для него (и обновит статус слота и создаст запись поста). Если указан topic\_override без slot\_id, то создаётся **внеплановый черновик** (можно сразу не публиковать). Если ничего не указано, агент сам определит ближайший слот в календаре для данного канала (например, на сегодня) и выполнит полный цикл для него.
  - **Ответ:** возвращает объект поста (черновика) с контентом:

    {\
    `  `"post\_id": "uuid-post-111",\
    `  `"channel\_id": 123456,\
    `  `"slot\_id": "uuid-slot-789",\
    `  `"title": null,\
    `  `"text": "<b>Новый пост</b> ...",\
    `  `"status": "draft",\
    `  `"scheduled\_time": "2025-09-06T08:00:00Z"\
    }

    Здесь status: draft означает, что пост пока не опубликован (если слот запланирован на будущее).
- POST /posts/{post\_id}/publish – опубликовать конкретный пост немедленно. Это может использоваться для внеплановых постов. По сути, вызывает Publisher в режим instant-публикации: если пост привязан к слоту в будущем, можно либо перенести слот на сейчас, либо проигнорировать слот. **Ответ:** 200 OK или ошибка с описанием.
- DELETE /posts/{post\_id} – удалить черновик или отменить запланированный пост (если не опубликован). Например, если авто-сгенерированный пост не понравился и его решили не использовать.
- **Мониторинг метрик (Metrics):**
- GET /metrics/{channel\_id} – получить суммарные метрики канала: средний ER, рост подписчиков (если доступно от Invite Service), количество постов, и др. Можно фильтровать по периоду (например, параметры ?from=2025-09-01&to=2025-09-30).
- GET /metrics/post/{post\_id} – получить метрики конкретного поста (как есть в таблице metrics, включая вычисленные ER/CTR).
- Возможно, метрики также передаются в административную панель через отдельный аналитический сервис, но базовые endpoints предоставляются для удобства интеграции.
- **Системные (Orchestrator control):**
- POST /orchestrator/onboard – (соответствует запуску агента по команде) инициализирует нового пользователя/канал. Если пользователь хочет подключить своего бота к каналу, по этому вызову создаётся новая стратегия v1 (как POST /strategies, можно рассматривать как враппер над ним), формируется базовая сетка слотов. Требуется channel\_id и данные для стратегии (либо ссылка на существующий шаблон стратегии).
  - *В будущих реализациях может быть полуавтомат: т.е. Onboard может брать ID канала, подключаться через Integration Service, подтягивать базовую информацию, и создавать дефолтную стратегию.*
- POST /orchestrator/run-day-slot – запуск дневного цикла *вручную* для указанного слота или канала. Принимает JSON с channel\_id и опционально slot\_id. Если slot\_id не указан – генерирует для ближайшего (то же, что /posts/generate без параметров, но может сразу и публиковать). Предназначен для ручного триггера вне расписания (например, форсировать публикацию сейчас).
- POST /orchestrator/weekly-update – вручную запустить еженедельную оптимизацию (если по какой-то причине нужно внепланово). Тело запроса: { "channel\_id": 123456 }. Агент пересчитает веса рубрик, обновит календарь и промпты как описано в разделе 2 (результаты фиксируются в БД).
- POST /orchestrator/monthly-review – вручную запустить процесс ежемесячной ревизии стратегии для канала. Тело: { "channel\_id": 123456 }. Агент соберёт данные, вызовет генерацию новой стратегии (скорее всего, синхронно это долго, поэтому endpoint сразу возвращает 202 Accepted, а процесс идёт асинхронно). По завершении обновится таблица strategies (добавится новая версия) и календарь.

**Аутентификация и безопасность API:** Все запросы требуют заголовок Authorization: Bearer <JWT>. JWT проверяется на валидность и срок. Также проверяется, что пользователь имеет доступ к channel\_id из запроса (например, маппинг user->channels хранится в базе Invite Service или общем профиле). Для повышенных прав (например, запуск monthly-review) можно требовать роль "admin". Доступ к особо чувствительным операциям (onboard, monthly-review) можно ограничить, чтобы злоумышленник не перегрузил систему частыми ревизиями. В Vault хранятся секреты JWT (например, signing secret или public key для проверки, а также, при необходимости, refresh tokens для Integration Service).

**Пример запроса и ответа:**\
Запрос: GET /strategies/123456/active\
Ответ:

{\
`  `"channel\_id": 123456,\
`  `"version": 2,\
`  `"persona": "Предприниматель-эксперт, дружелюбный тон...",\
`  `"pillars": ["Продажи", "Маркетинг", "SelfGrowth"],\
`  `"weights": {"Продажи": 0.3, "Маркетинг": 0.5, "SelfGrowth": 0.2},\
`  `"created\_at": "2025-10-01T00:00:00Z"\
}

Запрос: POST /posts/generate (без параметров, агент сам решит слот)\
Ответ (черновик создан):

{\
`  `"post\_id": "c1e2d3-uuid",\
`  `"channel\_id": 123456,\
`  `"slot\_id": "a1b2c3-uuid",\
`  `"text": "<p>Привет! Сегодня поговорим о новой технике продаж...</p>",\
`  `"status": "draft",\
`  `"scheduled\_time": "2025-09-05T18:00:00Z"\
}

*(В реальности text может содержать markdown-разметку, при необходимости Frontend его оформит. В status “draft” – значит не опубликован; если б сразу опубликовался, было бы “posted”.)*
## <a name="очереди-и-задачи-celery"></a>6. Очереди и задачи Celery
Для фонового выполнения длительных операций и планирования расписания используется Celery. Компоненты:

- **Celery Broker и бэкенд:** в конфигурации проекта Celery настроен либо на Redis (например, redis://) либо RabbitMQ (pyamqp://). Можно использовать уже существующий Redis/RabbitMQ в проекте. Результаты задач можно не хранить (или сохранять краткосрочно в Redis).
- **Планировщик задач (Celery Beat):** запускается вместе с сервисом (или как отдельный процесс), считывает расписание. Настроены следующие периодические задачи:
- **Daily slot check:** каждые, скажем, 5 минут Celery Beat запускает задачу, которая проверяет, нет ли слотов, запланированных в ближайшее время, которые ещё не запущены. Можно оптимизировать: хранить флаг следующего неисполненного слота и запускать точно в нужное время. Для простоты реализуем:
  - Задача check\_and\_run\_slots() достает из calendar\_slots записи где dt <= now() + δ (например, δ=5мин) и status = draft (ещё не выполнено). Для каждого такого слота отправляет задачу Orchestrator'у:
  - Отправляется задача tasks.run\_slot(channel\_id, slot\_id) в очередь content\_generation.
  - В качестве альтернативы: можно использовать Celery Beat с crontab/clocked tasks, но тогда для каждого слота надо динамически добавлять. Проще оставить регулярную проверку.
- **Weekly update:** например, каждое воскресенье ночью (cron: 0 0 \* \* SUN) запускается задача tasks.weekly\_update(channel\_id) для каждого активного канала. Реализация: можно заранее знать список каналов (хранить в конфиге или запросить DISTINCT channel\_id из strategies). Celery Beat может запускать общую задачу, которая сама переберет каналы и для каждого запустит подзадачу оптимизации.
- **Monthly review:** аналогично, по календарю – скажем, первого числа каждого месяца в 02:00 запускается задача tasks.monthly\_review(channel\_id) для каждого канала (или по очереди).
- **Telemetry collection:** можно настроить задачи сбора метрик. Например, каждый час запускать tasks.collect\_metrics(1h) (она пройдет по постам, у которых прошло ~1 час с публикации, и снимет метрику), аналогично раз в сутки и раз в неделю. Либо поставить три отдельных периодических задачи, привязанных ко времени (через crontab):
  - 0 \* \* \* \* – каждый час, вызвать сбор метрик за 1h
  - 0 0 \* \* \* – каждый день полночь, сбор 24h метрик
  - 0 0 \* \* MON – раз в неделю, сбор 7d метрик (понедельник полночь для постов прошлой недели).
- **Очереди Celery:** Можно разделить очереди, чтобы тяжелые задачи не мешали легким:
- content\_generation – очередь для задач генерации контента (дневной цикл). Эти задачи могут быть длительные (несколько секунд или минут на сбор данных и генерацию), поэтому стоит выделить воркеры с достаточным таймаутом.
- optimizations – очередь для weekly и monthly задач. Они тоже могут быть тяжелыми (особенно monthly, с вызовом GPT-4). Можно выполнять их на тех же воркерах или выделить отдельный, чтобы генерация постов не останавливалась из-за долгой ревизии.
- metrics – очередь для задач телеметрии (быстрые и легкие запросы, можно обработать отдельно).
- Если используется RabbitMQ, очереди настраиваются как routing\_key или отдельные named queues, воркеры подписываются соответственно.
- **Задачи (Tasks) реализации:** В модуле tasks.py (или нескольких):
- run\_slot(channel\_id, slot\_id) – основная задача ежедневного поста. Реализует последовательность:
  1. Загрузить контекст: strategy = db.get\_active\_strategy(channel\_id) и slot = db.get\_slot(slot\_id) (через SQLAlchemy или queries). Orchestrator готовит **контекст промптов**: persona, тональность, тема слота.
  1. Вызвать Research: собрать источники. Это можно делать параллельно:
  1. Запустить суб-задачу/функцию fetch\_web\_sources(topic, hours=72).
  1. Параллельно fetch\_tg\_sources(topic, hours=72).
  1. Подождать их завершения (если Celery, можно использовать группировку или chord, но проще синхронно вызвать функции, т.к. внутри они сами ходят по API).
  1. Результат: списки найденных материалов.
  1. Вызвать Insight Agent: insights = extract\_insights(web\_sources + tg\_sources). Функция формирует тезисы.
  1. Writer:
  1. draft\_text = writer\_generate\_draft(strategy, slot, insights) – используя локальную LLM. Эта функция внутри использует Prompt Generator, формирует промпт для черновика и вызывает модель (например, через библиотеку huggingface/transformers или через API локального сервера модели).
  1. final\_text = writer\_polish(draft\_text, high\_priority=slot.high\_priority) – доводка. Если high\_priority=true или, например, длина поста большая, вызывается API LLM (GPT-4) через соответствующий клиент. Если нет – может вызвать более быстрый режим или просто вернуть draft\_text без изменений (или легкое редактирование локально).
  1. Style: styled\_text = style\_apply(final\_text, persona\_rules=strategy.persona, tone=strategy.tone\_guide). Эта функция применит правила стиля. Также вызывается проверка качества: lint\_report = style\_lint(styled\_text) – орфография, длина, запрещенные слова. Если lint\_report обнаружил критичные проблемы, можно пометить флаг модерации.
  1. Art: assets = get\_visuals(styled\_text, topic=slot.pillar). Получает либо URL картинки, либо генерирует. Это может быть относительно долгим (генерация ~5-10 секунд), поэтому можно выполнять асинхронно. Но в ежедневном цикле допустимо синхронно ждать. Возвращает список ресурсов (обычно 0 или 1 изображение для простоты).
  1. Пост-обработка:
  1. Анти-плагиат: вызвать функцию plagiarism\_check(styled\_text). Она берет embedding текста и ищет близкие векторы во внешнем корпусе и базе своих постов. Также может использовать шингл-анализ. Возвращает plagiarism\_score. Если score выше порога (например >0.7 схожести или >30% текста совпадает с известным) – запускается процедура переписывания: можно вызвать writer\_polish снова с дополнительным промптом "перефразируй сильнее, убери прямые цитаты", либо отметить пост как требующий ручной проверки. В данной реализации, сделаем автокоррекцию: при высоком плагиате вызываем маленькую модель или правила, которые перефразируют подозрительные предложения.
  1. Модерация: проверить lint\_report и styled\_text на наличие запрещенного. Если найдена токсичная лексика или запретные темы (например, упомянутые в anti\_topics), то либо автоматически убрать/заменить, либо пометить пост для ручной проверки. Здесь можно либо вырезать проблемные места, либо заменить на нейтральные формулировки. Все инциденты логгировать (audit log).
  1. Сохранение: создать запись в posts со статусом draft, сохранить полный текст и данные проверок (lint, plagiarism).
  1. Publisher: если slot.dt (время публикации) уже в прошлом или ближайшее время (например, слот на сейчас) – выполнить немедленно publish\_post(post\_id). Иначе – запланировать. Для отложенной публикации можно воспользоваться функцией Celery eta: отправить задачу publish\_post(post\_id) в очередь Publisher с указанием ETA = времени slot.dt. Либо использовать Integration Service способ отложенной отправки. В нашем случае:
  1. schedule\_publish(post\_id, run\_at=slot.dt) – наша функция, которая либо вызовет Celery task с eta, либо сохранит в БД что нужно опубликовать и отдельный планировщик поймает. Celery с eta проще. Publisher через Integration Service публикует и обновляет posts.status на posted или error.
  1. Результат: если всё прошло, calendar\_slots.status пометить как scheduled (если отложено) или posted (если сразу вышло). Orchestrator возвращает успех.
  1. Пример псевдокода задачи:

     @celery.task(name="run\_slot")\
     def run\_slot(channel\_id, slot\_id):\
     `    `slot = Calendar.get(slot\_id)\
     `    `strategy = Strategy.get\_active(channel\_id)\
     `    `ctx = Memory.load\_persona\_and\_rules(strategy)\
     `    `# 1. Research\
     `    `tg\_data = fetch\_tg\_sources(slot.pillar, hours=72)\
     `    `web\_data = fetch\_web\_sources(slot.pillar, hours=72)\
     `    `sources = normalize\_and\_dedup(tg\_data + web\_data)\
     `    `# 2. Insights\
     `    `insights = Insight.extract(sources)\
     `    `# 3. Draft & Polish\
     `    `draft = Writer.generate\_draft(ctx, slot, insights)\
     `    `final = Writer.polish(draft, priority=slot.high\_priority)\
     `    `# 4. Style & lint\
     `    `styled = Style.apply(final, persona=ctx.persona)\
     `    `report = Style.lint(styled)\
     `    `# 5. Visuals\
     `    `assets = Art.find\_or\_create(slot.pillar, styled)\
     `    `# 6. Checks\
     `    `plagiarism\_score = Plagiarism.check(styled)\
     `    `if plagiarism\_score > 0.3:\
     `        `styled = Writer.rewrite\_avoid\_plagiarism(styled)\
     `    `moderation\_flags = Moderation.check(styled, report)\
     `    `if moderation\_flags.blocking:\
     `        `return fail("Content not allowed")\
     `    `# 7. Save draft\
     `    `post = Post.create(slot\_id, styled, assets, checks=report, plagiarism=plagiarism\_score)\
     `    `# 8. Publish or schedule publishing\
     `    `if slot.dt <= now()+5min:\
     `        `Publisher.publish(post, channel\_id)\
     `    `else:\
     `        `Publisher.schedule(post, slot.dt, channel\_id)\
     `    `return {"post\_id": post.id, "status": post.status}

     *(Это иллюстративно, фактическая реализация разбита на функции.)*
- publish\_post(post\_id) – задача Publisher, которая вызывается либо напрямую, либо отложенно. Она загружает пост и через Integration Service выполняет отправку. Оборачиваем вызов в try/except:
  - При успехе: обновляем posts.status = posted, posts.published\_at = now(), а в calendar\_slots.status ставим posted.
  - При исключении (например, сеть недоступна или FloodWait): если это FloodWait, можно обработать и повторить через указанный Telegram API интервал. Если другая ошибка – ставим статус error и кидаем исключение, чтобы Celery мог ретраить. Celery настроить retries: например, max\_retries=3, countdown=60 (будет три раза пытаться раз в минуту). После 3 неудач статус слота можно пометить как failed и перенести его на позже (например, +час или в конец календаря).
- weekly\_update(channel\_id) – собирает данные за неделю:
  - Получить все посты канала за последние 7 дней и их метрики (из metrics).
  - Рассчитать средний ER по каждому pillar (рубрике) и формату. Например, словарь engagement\_by\_pillar = {pillar: ER}.
  - Определить новые веса: возможно, нормировать так, чтобы сумма = 1, увеличив долю тех, у кого ER выше среднего, уменьшив у тех, у кого ниже.
  - Обновить JSON strategies.weights для активной стратегии.
  - Сгенерировать “дельты” для промптов: на основе наблюдений, сформировать текст рекомендаций. Например, если определено, что утренние посты слишком длинные – пометить, что для утренней рубрики уменьшить target\_length. Эти изменения записываются в prompts (новая версия или параметр).
  - Обновить календарь: возможно, поменять некоторые будущие calendar\_slots.pillar согласно новым весам (перетасовать темы). Это можно сделать, вызвав логику Calendar Service: например Calendar.reflow(channel\_id). Он посмотрит на новые веса и перемешает/заменит некоторые слоты (но соблюдая непрерывность сюжетных нитей – например, если была запланирована серия постов, их трогать не будет).
  - Записать факт оптимизации: можно залогировать событие, или сохранить в БД что стратегия тюнингована в такой-то день.
  - *Задача должна выполняться быстро*, поэтому сложный анализ не делаем тут – в основном агрегаты и небольшие правки.
- monthly\_review(channel\_id) – более долгий процесс:
  - Собрать все посты за месяц + их метрики + извлечь ключевые тренды извне: *Можно подключить Research Agent с более широким запросом: например, собрать топ-5 новостей месяца по основным темам канала.*
  - Сформировать сводный отчет (например, в текстовом виде: что сработало, что нет, какие новые идеи появились).
  - С помощью сильной LLM (GPT-4) сгенерировать новый документ стратегии: отправить в модель текущую стратегию + сводку по итогам + идеи и попросить выдать обновленную стратегию. Полученный текст разобрать на поля: новые pillars, новые anti\_topics, скорректированный tone\_guide, и т.д.
  - Создать новую запись strategies с версией +1. Старую пометить неактивной (или оставить как историю).
  - Перегенерировать контент-план (calendar\_slots) на следующие ~4 недели. Здесь можно сразу заложить основные сюжетные линии на месяц вперед (например, Strategy может вернуть “контентное обещание” аудитории на месяц – его нужно разложить по неделям). Calendar Service (или функция) берёт новую стратегию и строит расписание: какие рубрики в какие дни, сколько постов в неделю, и создает записи в БД.
  - Optional: Определить, какие промпты стоит обновить. Если стратегия сильно поменяла тон, то Prompt Generator обновит шаблон персона или Writer.
  - Данная задача может занимать несколько минут (вызов API модели), поэтому её лучше выполнять асинхронно. При запуске через Celery, можно сделать её не ретраящейся (чтобы не задублировать стратегию). Если не удалось (например, GPT-API не ответил) – записать ошибку в лог, оставить старую стратегию.
- **Workflow через очереди/events:** В перспективе, каждая стадия может работать как отдельная задача, сигнализируя о завершении через события (RabbitMQ/NATS). Например:
- research.corpus\_ready (когда Research Agent собрал данные),
- insights.ready(slot\_id) (когда инсайты выделены),
- writer.draft\_ready(slot\_id) (когда черновик текста готов),
- style.ready(slot\_id) (стиль применён),
- art.assets\_ready(slot\_id) (подобраны/созданы визуалы),
- post.scheduled(slot\_id) (пост поставлен в расписание на отправку),
- post.posted(post\_id) (пост успешно отправлен).
- telemetry.24h(post\_id) (через 24ч собраны метрики),
- optimizer.delta\_applied(channel\_id) (новые веса применены),
- strategy.updated(channel\_id, version) (стратегия обновлена до vN+1),
- calendar.updated(channel\_id) (календарь перестроен).

Эти события могут логироваться или обрабатываться для дополнительных действий (например, уведомить пользователя, что стратегия обновилась). Первоначально можно обойтись без явных событий, но архитектура их предусматривает.

- **Отказоустойчивость задач:** Celery задачи настроены с авто-ретраем при нефатальных сбоях (например, сеть). Для критических сервисов (Telegram, веб-поиск) можно настроить 3 попытки с увеличивающимся интервалом. Если задача окончательно провалилась (например, пост не удалось опубликовать), это не блокирует очередь – ошибка логируется, и система продолжает дальше. Orchestrator помечает слот как пропущенный и может перенести его на конец очереди (след. день).

В итоге, очереди и задачи обеспечивают бесперебойную генерацию контента в нужные моменты, разгружая основной поток выполнения (FastAPI обработчики). Большинство действий выполняется асинхронно, позволяя масштабировать воркеры при росте нагрузки (например, если много каналов подключат агентов, можно запустить больше Celery-воркеров).
## <a name="x6ff8c43e69e46ec5d102100ccd6dbc3568422cd"></a>7. Контрольные точки, мониторинг и отказоустойчивость
Для контроля работы системы и качества контента предусмотрены следующие механизмы:

- **Мониторинг и телеметрия:** Микросервис интегрируется с существующей системой мониторинга (например, Prometheus + Grafana, Loki/ELK для логов).
- В коде предусмотрены метрики Prometheus (через prometheus-client): например, counters evo\_posts\_generated\_total, evo\_posts\_published\_total, evo\_errors\_total (с лейблами типа error\_type), histogram для времени генерации поста, gauge текущих задач в очереди и т.п.
- **TimescaleDB / ClickHouse:** метрики эффективности постов, сохранённые в БД, могут дублироваться в специализированное хранилище для аналитики. Например, TimescaleDB (расширение Postgres) позволит строить временные ряды просмотров, или ClickHouse может использоваться для быстрых выборок по логам/метрикам. Optimizer, впрочем, читает метрики из обычной БД, так что Timescale не обязателен, но для внешнего анализа – да.
- **Дашборды:** Следует настроить графики: количество постов в день, средний ER по каналам, процент вовлеченности по рубрикам, количество ошибок публикаций. Также важен мониторинг Celery очередей (очередь не должна расти сильно, tasks failing).
- **Логи:** Логирование важно для отладки AI. Все ключевые события (начало генерации, использование fallback, результат модерации, ошибка отправки) логируются с уровнем INFO/ERROR. Используем структурированные логи (JSON), которые собираются в централизованный Loki/ELK.
- **Traces:** Опционально, подключается OpenTelemetry SDK, чтобы строить трассировки pipeline-а поста. Например, одна трасса включает спан Research, спан Writer, и т.д., чтобы видеть где задержки. Эти трассировки могут идти в Jaeger или Grafana Tempo.
- **Обработка ошибок и fallback-решения:** В системе предусмотрены альтернативные пути при сбоях:
- Если **веб-ресурсы недоступны** или не возвращают ничего (например, поисковый API падает): Research Agent использует **локальный корпус** – т.е. последние доступные данные. Например, у нас могут быть сохранены последние 2 недели статей/новостей (накапливаем в БД или файлах). Агент выберет оттуда что-то релевантное теме. Пост при этом пометит, что “новостей за сегодня нет, но вот недавний кейс…”. Таким образом, пост все равно выйдет, хоть и без “горячих” новостей.
- Если **LLM API (GPT-4) не ответил** или превысил время: Orchestrator не проваливает весь пост, а **деградирует** gracefully. Например, если на этапе Polish GPT-4 не дал ответ за допустимое время (скажем, >30 секунд), Orchestrator логирует warning и переходит к запасному варианту: берёт черновик и полирует его локальной моделью попроще (или вообще пропускает polisher). Возможно, пост будет не столь идеален, но зато будет готов вовремя. Также, если текст слишком длинный для локальной модели, можно применить стратегию **map-reduce** суммаризации: разбить текст на части, суммаризировать по частям.
- Если **публикация провалилась:** Например, Integration Service вернул ошибку, Telegram API не отвечает, или пойман FloodWait (Telegram сказал "try again in 30 seconds"). Publisher выполняет retry:
  - При FloodWait – специальная обработка: задача publish\_post ставит паузу (спит или откладывает выполнение) на указанное число секунд, потом пробует снова. Этот сценарий не считаем ошибкой, просто задержка.
  - При других сетевых ошибках: Celery автоматически ретраит 2-3 раза. Если после максимальных попыток не удалось, задача переходит в состояние провала (можно настроить Dead Letter Queue). В БД posts.status помечается error. Orchestrator при этом помечает calendar\_slots.status = draft или failed. Возможный сценарий: отложить этот слот на позже – например, добавить +1 час к времени и попробовать заново (с новой задачей). Также уведомить админа (возможно, отправив сообщение в админский чат) о проблеме.
- Если **анти-плагиат показал высокий процент** заимствования: Автоматическая перегенерация. Например, если plagiarism\_score > 0.3 (30% текста совпадает с известными источниками), система может:
  - Попытаться перефразировать проблемные куски: запустить функцию rewrite\_text(styled\_text) – которая заменит формулировки, сохраняя смысл. Это может быть вызов той же локальной модели с промптом "перефразируй этот текст другими словами".
  - Обрезать длинные цитаты, если они есть, и оставить их в виде пересказа.
  - После переписки повторно проверить показатель; если он существенно снизился – ок. Если нет – можно выставить флаг в посте checks.plagiarism\_flag = true и все равно опубликовать, но система в отчёте отметит, что возможен плагиат. Администратор потом увидит и решит.
- **Ошибка модели или кода:** Если любое исключение случилось внутри генерации (например, упала библиотека, OutOfMemory на GPU и т.п.), задача Celery ловит ее. Orchestrator должен аккуратно обработать: отмечаем слот как неуспешный, и можно попытаться позже (либо вручную, либо следующей итерацией). Стараться, чтобы падение одной части (например, Art) не останавливало весь процесс: если Art Director не смог сгенерировать картинку – залогировать, но продолжить без изображения.
- **Модерация контента:** Перед публикацией пост проходит автоматическую модерацию на соответствие правилам:
- **Toxicity/NSFW:** Текст прогоняется через локальный классификатор токсичности и нежелательного контента. Если пост содержит маты, оскорбления, призывы к насилию и прочее – агент либо очищает текст (например, замены \*\*\*\*, эвфемизмы), либо блокирует публикацию. В корпоративном контексте, скорее блокирует и сообщает, что пост не прошёл модерацию.
- **Запрещённые темы:** Сверяем текст с списком anti\_topics из стратегии. Если пост умудрился затронуть нежелательную тему, нужно отфильтровать этот фрагмент или отменить публикацию. Например, если anti\_topics содержит “Политика”, а в инсайтах затесалась политическая новость, то Insight Agent или Moderation должны выкинуть этот инсайт ещё до генерации. Контрольный пункт модерации, тем не менее, повторно проверяет финальный текст.
- **Правильность оформления:** Линтер (орфография, ссылки) уже применялся – на этапе Style Adapter были получены lint\_report. Если критические ошибки (например, орфографические опечатки) – можно автоматически исправить (используя, например, библиотеку проверки орфографии), либо сообщить администратору.
- **Audit Log:** Все случаи модерационного вмешательства пишутся в специальный лог или таблицу (audit): какой пост, что удалено/заменено, почему. Это полезно, чтобы потом обучить модель или поправить стратегию (например, добавить новое запрещенное слово).
- **Антиплагиат:** уже описан выше. Он тоже часть модерации, чтобы не публиковать скопированный текст.
- **Протестированные контрольные точки:** перед финальной публикацией Orchestrator может пройтись чеклист:
- Заголовок присутствует (если нужен), длина поста в допустимых пределах (Telegram макс ~4096 символов для сообщения).
- У всех внешних ссылок есть UTM-метки (если стратегия требует отслеживать трафик).
- Если пост рассчитан на обсуждение – прикреплён ли опрос/кнопка (возможно, проверить структуру assets).
- Все изображения доступны (например, сделать HEAD запрос к URL, убедиться что не 404).
- Это своего рода QA перед отправкой. Если что-то не так – лучше поставить статус draft и не отправлять, попросить человеческого вмешательства.

Таким образом, система устойчива к сбоям: она либо решает проблему автоматическими fallback-ами, либо аккуратно отключает проблемный функционал, либо откладывает задачу и уведомляет ответственных. Критичные инциденты (не опубликован пост, нарушены правила) фиксируются, чтобы команда могла реагировать.
## <a name="архитектурные-best-practices"></a>8. Архитектурные best practices
При реализации данного микросервиса следует учитывать лучшие практики архитектуры, чтобы обеспечить масштабируемость, безопасность и поддержку в промышленной среде:

- **Асинхронность и неблокирующий I/O:** Весь ввод-вывод (запросы к внешним API, БД) осуществляется асинхронно (используем возможности FastAPI с async endpoints и await внутри, а также асинхронные клиенты для HTTP, БД (например, asyncpg, httpx, Telethon async)). Это позволяет эффективно использовать ресурсы, особенно при одновременной работе над несколькими постами.
- Celery задачи могут быть как синхронными (они исполняются в воркерах, параллельно), так и асинхронными (Celery 5+ поддерживает async def tasks). Для совместимости можно оставить sync функции в tasks, но внутри них можно запускать asyncio (например, use asyncio.run or ensure loop).
- Генерация контента – процесс последовательный по шагам, но можно распараллелить независимые части: в Research Agent мы параллельно тянем веб и телеграм, в Writer (draft -> polish) можно сразу после отправки draft в API LLM продолжать другие действия (впрочем, там зависит от результата).
- Важно не блокировать основной поток FastAPI: все длительные операции запускаются как background tasks или Celery tasks. REST API откликается быстро (например, при POST /generate можно сразу вернуть draft\_id и статус "генерация запущена" или дождаться завершения по желанию).
- **Streaming:** Если в будущем потребуется, можно сделать стриминг ответа модели (когда генерируется текст поступательно), но в рамках задания это излишне.
- **Изоляция модулей и разделение ответственности:** Хотя все компоненты входят в один микросервис, стоит разделить их логически:
- Кодовую базу структурировать по модулям: orchestrator.py, agents/research.py, agents/writer.py, agents/style.py, agents/optimizer.py, services/publisher.py и т.д. Каждый содержит классы/функции, реализующие логику соответствующего агента.
- Это упростит возможность вынести модуль в отдельный сервис, если потребуется. Например, agents/research.py может потом стать основой отдельного Research-Web сервис.
- Каждый агент-логика не должен напрямую заниматься тем, что вне его зоны: Writer генерирует текст и не заботится как он публикуется, Publisher не лезет в генерацию текста и т.п. Orchestrator выступает посредником.
- **Изоляция по данным:** Лучше избежать прямого обращения к чужим таблицам: EvolutionAI использует свои таблицы. Например, не писать напрямую в таблицы Invite Service или Parsing Service – взаимодействие только через их API. Это предотвращает сильную связанность и проблемы при изменении чужой схемы.
- **Безопасность данных и секреты:** Используем Vault для всех ключей, как описано. Также соблюдаем минимально необходимые привилегии:
- У PostgreSQL пользователя для этого сервиса – гранты только на свои таблицы (и на SELECT чужих, если требуется, но лучше не надо).
- Доступ к Vault – через отдельный policy, которая даёт право читать нужные пути (например, secret/data/evoai/\*).
- При работе с внешними API соблюдаем ограничения: например, OpenAI API ключ хранить только в памяти, не логировать запросы целиком (особенно если они могут содержать персональные данные).
- JWT аутентификация – проверять не только подпись, но и использовать audience, issuer поля, если они устанавлены, чтобы токены от другого сервиса не подошли.
- Все endpoints валидируют входные данные (с помощью Pydantic схем) – защищаемся от SQL-инъекций (ORM сам по себе, но мало ли), от XSS (хотя мы не прямо отображаем, но если интерфейс потом покажет текст поста, он уже в безопасном HTML).
- **Обработка флуктуаций Telegram:** Telegram API может быть нестабильным:
- **Rate limits:** Telegram накладывает ограничения на отправку сообщений (не более ~20 сообщений/мин в публичные каналы, и т.д.). Publisher должен учитывать это: например, если агент ведет **несколько каналов** на одном аккаунте, суммарно может превысить лимит. Решение: вводим **токен-бакет** – храним в Redis счетчик отправленных сообщений за интервал, и если превышает – задерживаем. Integration Service возможно уже имеет встроенные паузы (Telethon автоматически обрабатывает FloodWait), но лишняя защита не помешает.
- **Connectivity:** Если Telegram серверы недоступны (случается блокировка или сбой) – Publisher должен быстро фейлить с retry = False, т.к. дальнейшие попытки бессмысленны до восстановления связи. В таком случае агент может уведомить пользователя через альтернативный канал (email или лог) о проблеме и будет ждать следующего слота.
- **API changes:** Telegram API обновляется, но используя Integration Service, мы абстрагированы – он должен быть обновлен, если что. Главное – следить за версиями Telethon/Pyrogram.
- **Two-factor & login:** Через Integration Service нам не нужно хранить номера телефонов или коды – всё уже заведено. Если Integration Service требует, агент может запросить у Vault свежий session key. Если сессия протухла – Integration Service скажет error, тогда придется вручную переавторизовать. В рамках автопилота, предусмотреть, что publish\_post может вернуть ошибку "AuthFailed", тогда агент не будет ретраить, а пометит канал как требующий внимания (например, статус в своей БД "authorization\_required").
- **Эффективность вычислений:**
- **Локальные vs API модели:** Следовать политике экономии: максимум операций выполнять локально. Например, суммаризацию нескольких статей лучше сделать локально одной моделью, чем 5 раз дергать внешнюю. API-модели использовать точечно: финальная обработка текста (и то не всегда), генерация стратегии раз в месяц.
- **Профилирование:** Желательно замерять время каждого шага (через logs or traces). Узкие места – веб-поиск (иногда долгий) и LLM вызовы. Можно оптимизировать: кэшировать результаты поисковых запросов (хранить в Redis на несколько часов). Также, если два слота очень близки по теме (например, два поста недели продолжают тему), можно реиспользовать часть ресёрча или инсайтов.
- **Batching:** Если в один момент нужно собрать несколько внешних ресурсов, можно выполнять запросы параллельно (asyncio.gather for HTTP calls). Также, если используется модель на GPU, можно паковать несколько задач, но это уже сложнее, пока не нужно.
- **Режимы качества:** Можно предусмотреть **tiers** – профили качества/затрат, настраиваемые для канала. Например, low\_cost – всегда использовать только локальные модели, premium – чаще звать GPT-4. Эта настройка хранится в стратегии или канале. Orchestrator при выборе модели проверяет tier: если low\_cost – даже high\_priority посты делает локально и просто логирует необходимость ручной проверки, если premium – может даже черновики делать более мощной моделью для лучшего стиля. Это помогает масштабировать под бюджет пользователя.
- **Использование GPU:** Если сервер имеет GPU, для локальных моделей (Mistral, Llama) используем ускорение. Следует предусмотреть, что модель грузится один раз при старте и далее переиспользуется (чтобы не тратить время на загрузку на каждое задание). В коде инициализации Writer Agent можно загрузить модель и держать в глобальной переменной, используя потоки/асинхронность для запросов к ней.
- **Memory оптимизация:** Следить за объемом хранимых данных. Старые стратегии, посты, инсайты можно архивировать (например, не держать всё в оперативной памяти, а запрашивать из БД по необходимости). Векторное хранилище может расти, нужно или ограничивать (например, хранить эмбеддинги только последних N месяцев контента) или масштабировать его.
- **Сценарий деградации:** Если ресурс ограничен (например, мало RAM или CPU), можно временно отключать некоторые функции: например, Art Generation (лишить картинок, если GPU перегружен), или снизить размер модели (fallback на более компактную). Такие настройки могут быть конфигурационными (ENV flags).
- **Vault и секреты (best practice):**
- Никогда не хардкодить секреты или пути. Все sensitive info – через env variables, которые Vault Agent может провиженить или через direct API calls.
- Регулярно обновлять ключи (например, OpenAI ключи могут ротироваться).
- Минимизировать права: например, если EvolutionAI читает комментарии через Parsing Service, не нужно ему самому иметь ключ от Telegram, достаточно HTTP-токена к Parsing API.
- Логи не должны содержать секретные данные. При выводе URL, если там есть токены – маскировать.

В целом, проект следует 12-factor app методологии: конфигурация через окружение, логи в stdout (или централизовано), процессы масштабируемые. Контейнеризация (Docker) – образ на базе Python slim, только нужные зависимости (FastAPI, Celery, ML libs). Docker-compose соединяет компоненты, можно задать healthcheck (например, проверка что /health endpoint возвращает 200, а Celery воркер отвечает).
## <a name="выходные-требования-финальная-реализация"></a>9. Выходные требования (финальная реализация)
В результате должно получиться полноценное решение, готовое к непосредственному запуску и интеграции, без заглушек. **Все описанные компоненты и функции должны быть реализованы в коде** – т.е. никаких пустых функций pass, никаких искусственных имитаций. Микросервис должен **сразу работать** после генерации кода в Cursor:

- **Полная реализация логики:** Код должен содержать реальные вызовы там, где это предусмотрено:
- Интеграция с Parsing Service и Integration Service осуществляется через реальные HTTP-запросы (используя requests/httpx или через gRPC, если их API таков). Если API возвращает данные – код парсит и использует их.
- Взаимодействие с БД – через ORM (SQLAlchemy) или миграции – но главное, чтобы CRUD-операции реально записывали и читали из PostgreSQL. Не должно быть “фейковых” репозиториев в памяти.
- Вызовы моделей: для локальных LLM – можно использовать существующие модели/библиотеки (например, интеграция с HuggingFace Transformers pipeline для генерации текста). Для API LLM – использовать их SDK/HTTP (OpenAI API via openai Python lib, etc.) с ключами из Vault.
- Отправка в Telegram: использовать Integration Service (например, через HTTP API, или если Integration Service предоставляет SDK, подключить). **Не** ограничиваться принтом – реально сделать POST запрос и обрабатывать ответ.
- Функции модерации, антиплагиата – тоже реализовать (пусть и упрощённо, например, токсичность – список стоп-слов, плагиат – сравнение shingle). Главное, чтобы код выполнял проверки и принимал решения, а не просто оставлял # TODO.
- Все вспомогательные части (например, расчет нового веса рубрики) тоже кодируются, даже если это простое правило.
- **Готовность к сборке и запуску:** Проект, сгенерированный по этому ТЗ, должен собираться без ошибок. В частности:
- Имена классов, функций и модулей, упомянутые в тексте, должны совпадать в реализации. Например, если описан Post.create() или Calendar.reflow(), в коде действительно должен быть класс Post с методом create или функция reflow в модуле Calendar. Это нужно, чтобы Cursor (AI-помощник) правильно понял структуру.
- Зависимости (библиотеки) указать в requirements (FastAPI, Celery, etc., huggingface/transformers для LLM, httpx, SQLAlchemy, prometheus-client, etc.). **Dockerfile** и **docker-compose.yml** в задание не включаем, но подразумеваем, что они будут настроены аналогично другим сервисам.
- Не нужно генерировать тесты в этом задании, но код должен быть спроектирован так, чтобы тестирование было возможно (чистые функции для логики, конфигурируемые зависимости, например, URL других сервисов брать из ENV, чтобы в тесте можно было подменить на mock).
- **OpenAPI спецификация:** благодаря FastAPI, при запуске сервис автоматически предоставляет swagger (http://.../docs). Все endpoints должны быть задокументированы (описание, модели запросов/ответов через Pydantic) согласно написанному. Например, модель StrategyCreate, PostDraft, etc., чтобы удобнее пользоваться API.
- **Согласованность с существующим проектом:**
- Использовать те же подходы, что и в других микросервисах проекта. Например, если в проекте принята структура app/main.py для FastAPI и app/tasks.py для Celery – следовать ей. Если принято хранить конфигурацию в .env и загружать через Pydantic Settings – тоже придерживаться.
- Логирование в том же формате, что и остальные сервисы (например, structlog JSON или standard logging).
- JWT в других сервисах – вероятно, уже настроен. Наш сервис должен либо использовать общий библиотечный компонент для JWT валидации, либо настроить аналогично.
- Respect cross-cutting concerns: например, если в проекте есть Middleware для tracing, подключить его и в наш сервис.
- **Пригодность для генерации кода:** Данное техническое задание сформулировано таким образом, чтобы AI-ассистент (Cursor) мог однозначно понять структуру и приступить к генерации. Все названия и параметры продуманы и должны быть **валидны**. Требуется максимальная детализация, чтобы разработка была как можно более автоматической:
- Классы: Strategy, Calendar, Post, Telemetry, и т.д. – должны быть созданы согласно описанию.
- Поля моделей – соответствуют описанным схемам (типам данных PostgreSQL).
- Endpoints – реализовать согласно разделу 5, используя Pydantic-схемы для запросов/ответов.
- Celery tasks – согласно разделу 6, с именами и функциями.
- Любая специфичная логика (например, бандит-алгоритм) – можно упростить, но функцию оставить, чтобы потом улучшить.

В итоге, после копирования этого промпта в Cursor, должно сгенерироваться несколько модулей: модели (ORM схемы), API (FastAPI endpoints), фоновые задачи, интеграционные клиенты (например, для Parsing/Integration Service), и другие вспомогательные. Проект можно сразу запускать – он будет выполнять полный цикл: от onboard нового канала, через ежедневные посты, до эволюции стратегии, соответствуя изложенной архитектуре.

-----
