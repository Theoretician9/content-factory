"""
Parsing speed configuration for different risk/speed levels.

Provides predefined configurations for safe, medium, and fast parsing modes
with appropriate delays and rate limits for Telegram API.
"""

from enum import Enum
from typing import Dict, NamedTuple
from dataclasses import dataclass


class ParsingSpeed(Enum):
    """Parsing speed modes with different risk/speed tradeoffs."""
    SAFE = "safe"       # ğŸŸ¢ Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğ¹ (Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹) - Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ¸ÑĞº FloodWait/ban
    MEDIUM = "medium"   # ğŸŸ¡ Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ñ‹Ğ¹) - Ğ±Ğ°Ğ»Ğ°Ğ½Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸  
    FAST = "fast"       # ğŸ”´ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ (Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğ¹) - Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ, Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Ñ€Ğ¸ÑĞº


@dataclass
class SpeedConfig:
    """Configuration for a specific parsing speed."""
    # Basic delays (seconds)
    message_delay: float        # Delay between processing messages
    user_request_delay: float   # Delay between user data requests
    api_request_delay: float    # General API request delay
    
    # Rate limits (requests per minute)
    user_requests_per_minute: int   # User data requests limit
    api_requests_per_minute: int    # General API requests limit
    
    # Batch processing
    batch_size: int             # Messages processed in one batch
    batch_delay: float          # Delay between batches
    
    # FloodWait handling  
    max_retries: int           # Max retry attempts
    backoff_multiplier: float  # Exponential backoff multiplier
    
    # User-friendly description
    name: str
    description: str
    estimated_speed: str       # Estimated users per hour
    risk_level: str           # Risk description


# Predefined speed configurations based on research
SPEED_CONFIGS: Dict[ParsingSpeed, SpeedConfig] = {
    
    ParsingSpeed.SAFE: SpeedConfig(
        # Delays
        message_delay=2.0,          # 2 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸ÑĞ¼Ğ¸
        user_request_delay=3.0,     # 3 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹
        api_request_delay=1.0,      # 1 ÑĞµĞºÑƒĞ½Ğ´Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ API Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸
        
        # Rate limits  
        user_requests_per_minute=20,    # 20 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ² Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ
        api_requests_per_minute=30,     # 30 API Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ
        
        # Batch processing
        batch_size=10,              # 10 ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ
        batch_delay=5.0,            # 5 ÑĞµĞºÑƒĞ½Ğ´ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±Ğ°Ñ‚Ñ‡Ğ°Ğ¼Ğ¸
        
        # FloodWait handling
        max_retries=5,
        backoff_multiplier=2.0,
        
        # Description
        name="Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğ¹",
        description="ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ¸ÑĞº FloodWait Ğ¸ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ¾Ğº. ĞœĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾, Ğ½Ğ¾ Ğ½Ğ°Ğ´ĞµĞ¶Ğ½Ğ¾.",
        estimated_speed="~300-500 Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹/Ñ‡Ğ°Ñ",
        risk_level="ĞÑ‡ĞµĞ½ÑŒ Ğ½Ğ¸Ğ·ĞºĞ¸Ğ¹"
    ),
    
    ParsingSpeed.MEDIUM: SpeedConfig(
        # Delays
        message_delay=0.8,          # 0.8 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸ÑĞ¼Ğ¸
        user_request_delay=1.5,     # 1.5 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹
        api_request_delay=0.5,      # 0.5 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ API Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸
        
        # Rate limits
        user_requests_per_minute=40,    # 40 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ² Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ
        api_requests_per_minute=60,     # 60 API Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ
        
        # Batch processing
        batch_size=25,              # 25 ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ
        batch_delay=2.0,            # 2 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±Ğ°Ñ‚Ñ‡Ğ°Ğ¼Ğ¸
        
        # FloodWait handling
        max_retries=3,
        backoff_multiplier=1.5,
        
        # Description
        name="Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ñ‹Ğ¹)",
        description="ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸. Ğ˜Ğ½Ğ¾Ğ³Ğ´Ğ° Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹ FloodWait.",
        estimated_speed="~800-1200 Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹/Ñ‡Ğ°Ñ",
        risk_level="Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹"
    ),
    
    ParsingSpeed.FAST: SpeedConfig(
        # Delays
        message_delay=0.2,          # 0.2 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸ÑĞ¼Ğ¸
        user_request_delay=0.5,     # 0.5 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹
        api_request_delay=0.1,      # 0.1 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ API Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸
        
        # Rate limits
        user_requests_per_minute=90,    # 90 Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ² Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ
        api_requests_per_minute=120,    # 120 API Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ
        
        # Batch processing
        batch_size=50,              # 50 ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ
        batch_delay=0.5,            # 0.5 ÑĞµĞºÑƒĞ½Ğ´Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ±Ğ°Ñ‚Ñ‡Ğ°Ğ¼Ğ¸
        
        # FloodWait handling
        max_retries=2,
        backoff_multiplier=1.2,
        
        # Description
        name="Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ (Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğ¹)",
        description="ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ. Ğ’Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Ñ€Ğ¸ÑĞº FloodWait Ğ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ¾Ğº.",
        estimated_speed="~1500-2500 Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹/Ñ‡Ğ°Ñ",
        risk_level="Ğ’Ñ‹ÑĞ¾ĞºĞ¸Ğ¹"
    )
}


def get_speed_config(speed: ParsingSpeed) -> SpeedConfig:
    """
    Get configuration for a specific parsing speed.
    
    Args:
        speed: Parsing speed enum value
        
    Returns:
        SpeedConfig object with all timing parameters
    """
    return SPEED_CONFIGS[speed]


def get_available_speeds() -> Dict[str, Dict]:
    """
    Get all available speeds for frontend display.
    
    Returns:
        Dictionary with speed information for UI
    """
    return {
        speed.value: {
            'name': config.name,
            'description': config.description,
            'estimated_speed': config.estimated_speed,
            'risk_level': config.risk_level,
            'user_requests_per_minute': config.user_requests_per_minute,
            'message_delay': config.message_delay
        }
        for speed, config in SPEED_CONFIGS.items()
    }


def parse_speed_from_string(speed_str: str) -> ParsingSpeed:
    """
    Parse parsing speed from string value.
    
    Args:
        speed_str: String representation of speed ("safe", "medium", "fast")
        
    Returns:
        ParsingSpeed enum value, defaults to MEDIUM if invalid
    """
    try:
        return ParsingSpeed(speed_str.lower())
    except ValueError:
        # Default to medium if invalid speed provided
        return ParsingSpeed.MEDIUM


def calculate_estimated_time(user_count: int, speed: ParsingSpeed) -> Dict:
    """
    Calculate estimated parsing time for given user count and speed.
    
    Args:
        user_count: Number of users to parse
        speed: Parsing speed mode
        
    Returns:
        Dictionary with time estimates
    """
    config = get_speed_config(speed)
    
    # Estimate users per hour based on rate limits and delays
    users_per_hour = min(
        config.user_requests_per_minute * 60,  # Based on rate limit
        3600 / config.user_request_delay       # Based on delay
    )
    
    # Account for batch processing efficiency
    if config.batch_size > 1:
        batch_efficiency = 1.2  # 20% efficiency gain from batching
        users_per_hour *= batch_efficiency
    
    # Calculate time estimates
    estimated_hours = user_count / users_per_hour
    estimated_minutes = estimated_hours * 60
    
    return {
        'estimated_hours': round(estimated_hours, 2),
        'estimated_minutes': round(estimated_minutes, 1),
        'users_per_hour': round(users_per_hour),
        'speed_name': config.name,
        'risk_level': config.risk_level
    } 