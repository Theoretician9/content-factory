# CHECK LIST: Разработка Multi-Platform Parser Service

> **Этот файл — подробный чек-лист разработки мультиплатформенного микросервиса parsing-service. Сервис будет поддерживать парсинг данных из различных социальных платформ (Telegram, Instagram, WhatsApp и др.) через модульную систему адаптеров. Phase 1 фокусируется на Telegram согласно техническому заданию.**

## ЭТАП 1: Подготовка мультиплатформенной архитектуры

### 1.1. Анализ и переработка архитектуры
- [ ] Проанализировать существующий код parsing-service
- [ ] Создать план миграции к мультиплатформенной архитектуре
- [ ] Спроектировать абстрактную систему Platform Adapters
- [ ] Определить универсальные модели данных (platform-agnostic)
- [ ] Спроектировать API endpoints с параметром platform
- [ ] Создать архитектуру plugin-системы для новых платформ

### 1.2. Настройка универсальной базы данных PostgreSQL
- [ ] Создать отдельную БД для parsing-service (parsing_db)
- [ ] Настроить пользователя parsing_user с необходимыми правами
- [ ] Обновить строку подключения в docker-compose.yml
- [ ] Создать универсальные модели SQLAlchemy:
  - [ ] ParseTask (с полем platform: telegram/instagram/whatsapp)
  - [ ] ParseResult (универсальная структура + platform_specific_data JSON)
  - [ ] PlatformChat (обобщенная информация о чатах/группах/страницах)
  - [ ] PlatformUser (унифицированные данные пользователей)
  - [ ] ParseLog (логи с указанием платформы)

### 1.3. Интеграция с RabbitMQ (мультиплатформенные очереди)
- [ ] Настроить Celery для работы с RabbitMQ
- [ ] Создать очереди для разных платформ (telegram_queue, instagram_queue, whatsapp_queue)
- [ ] Создать очереди для разных приоритетов (low, normal, high) для каждой платформы
- [ ] Реализовать универсальную структуру задач:
  - [ ] user_id, link, platform, type, account_id, resume_point, status

### 1.4. Интеграция с Redis (состояния с namespacing)
- [ ] Настроить подключение к Redis для хранения состояний
- [ ] Реализовать класс для управления состояниями задач с platform namespacing
- [ ] Создать систему хранения FloodWait/Rate limit таймеров для всех платформ
- [ ] Настроить TTL для различных типов данных по платформам

## ЭТАП 2: Интеграция с существующими сервисами (мультиплатформенная)

### 2.1. Интеграция с Integration Service (все платформы)
- [ ] Изучить API Integration Service для получения аккаунтов всех платформ
- [ ] Реализовать HTTP клиент для взаимодействия с Integration Service
- [ ] Создать функции для получения аккаунтов с фильтрацией по platform:
  - [ ] Telegram аккаунты (phase 1)
  - [ ] Instagram аккаунты (планируется)
  - [ ] WhatsApp аккаунты (планируется)
- [ ] Реализовать алгоритм выбора оптимального аккаунта с учетом платформы

### 2.2. Интеграция с Vault (мультиплатформенные секреты)
- [ ] Настроить VaultClient с AppRole аутентификацией
- [ ] Реализовать получение секретов для всех платформ:
  - [ ] Telegram .session файлы и api_id/api_hash
  - [ ] Instagram API токены (планируется)
  - [ ] WhatsApp Business API токены (планируется)
- [ ] Создать функции для безопасного создания временных файлов/токенов
- [ ] Настроить пути в Vault: `kv/integrations/{platform}/sessions/{session_id}`

### 2.3. Интеграция с API Gateway (универсальная)
- [ ] Настроить JWT аутентификацию для parsing endpoints
- [ ] Реализовать middleware для извлечения user_id из JWT токена
- [ ] Создать декораторы для проверки прав доступа
- [ ] Добавить валидацию параметра platform в запросах

## ЭТАП 3: Реализация API endpoints согласно ТЗ

### 3.1. Endpoint добавления задач парсинга
- [ ] **POST /parser/queue** - основной endpoint
- [ ] Реализовать Pydantic схемы для валидации
- [ ] Добавить валидацию Telegram ссылок (формат t.me/username)
- [ ] Реализовать автоопределение типа (группа/канал)

### 3.2. Endpoints управления задачами
- [ ] **GET /parser/tasks** - список задач пользователя
- [ ] **GET /parser/tasks/{task_id}** - информация о конкретной задаче
- [ ] **POST /parser/tasks/{task_id}/pause** - поставить задачу на паузу
- [ ] **POST /parser/tasks/{task_id}/resume** - возобновить задачу
- [ ] **DELETE /parser/tasks/{task_id}** - удалить задачу

### 3.3. Endpoint поиска сообществ
- [ ] **GET /parser/search** - поиск по ключевым словам
- [ ] Реализовать параметры: q (query), offset, limit
- [ ] Интегрировать с Telethon для поиска публичных чатов

### 3.4. Endpoint выгрузки результатов
- [ ] **GET /parser/result/{task_id}** - получение результатов
- [ ] Реализовать поддержку форматов: JSON, CSV, NDJSON
- [ ] Создать структуру данных согласно ТЗ

## ЭТАП 4: Реализация Telegram парсинга с Telethon

### 4.1. Настройка Telethon клиента
- [ ] Установить Telethon в requirements.txt (версия 1.34.0+)
- [ ] Реализовать TelegramClient wrapper с обработкой ошибок
- [ ] Настроить создание клиента из .session файла

### 4.2. Парсинг групп (iter_participants)
- [ ] Реализовать парсинг участников Telegram групп
- [ ] Извлекать данные: user_id, username, full_name, language_code, status
- [ ] Добавить получение join_date (если доступно)

### 4.3. Парсинг каналов (get_messages)
- [ ] Реализовать парсинг сообщений из каналов
- [ ] Получать комментарии к сообщениям (если включены)
- [ ] Извлекать информацию о пользователях-комментаторах

### 4.4. Получение общей информации о чатах
- [ ] Реализовать извлечение метаданных чата
- [ ] Обработать различные типы чатов (супергруппы, каналы)
- [ ] Сохранять информацию в таблицу TelegramChat

## ЭТАП 5: Обработка ошибок и лимитов Telegram

### 5.1. Обработка Telegram API ошибок
- [ ] FloodWaitError - сохранение времени ожидания в Redis
- [ ] SessionExpiredError - пометка сессии как невалидной
- [ ] AuthKeyError - обработка проблем с ключом авторизации
- [ ] ChannelPrivateError - пропуск приватных каналов

### 5.2. Rate limiting и адаптивные паузы
- [ ] Реализовать счетчик запросов (200-300 без задержки)
- [ ] Добавить адаптивную паузу после превышения лимита
- [ ] Настроить безопасный лимит: 100 сообщений/сек

### 5.3. Resume functionality (восстановление задач)
- [ ] Сохранять offset_id и message_id в Redis
- [ ] Реализовать восстановление с последней позиции
- [ ] Обновлять прогресс задачи в реальном времени

## ЭТАП 6: Celery Worker и асинхронная обработка

### 6.1. Реализация Celery задач
- [ ] Создать основную задачу parse_telegram_chat
- [ ] Реализовать задачи для разных типов парсинга
- [ ] Добавить retry логику с экспоненциальным backoff

### 6.2. Управление аккаунтами в воркерах
- [ ] Реализовать алгоритм выбора аккаунта в задаче
- [ ] Добавить переключение аккаунтов при ban/flood
- [ ] Обновлять статус аккаунта в Integration Service

## ЭТАП 7: Безопасность и мониторинг

### 7.1. Безопасность и защита данных
- [ ] Все .session файлы только через Vault API
- [ ] Удаление временных файлов после использования
- [ ] Шифрование чувствительных данных в БД

### 7.2. Интеграция с мониторингом
- [ ] Добавить Prometheus метрики
- [ ] Настроить алерты в Alertmanager
- [ ] Создать Grafana дашборд для parsing-service

## ЭТАП 8: Тестирование и оптимизация

### 8.1. Unit тесты
- [ ] Написать тесты для всех основных функций
- [ ] Тесты для API endpoints с mock данными
- [ ] Тесты для Telegram парсинга с фиктивными клиентами

### 8.2. Интеграционные тесты
- [ ] Тесты взаимодействия с Integration Service
- [ ] Тесты работы с Vault (получение секретов)
- [ ] Тесты полного цикла: создание задачи → парсинг → результат

## ЭТАП 9: Деплой и production готовность

### 9.1. Подготовка к production
- [ ] Обновить docker-compose.yml для всех компонентов
- [ ] Настроить health checks для всех контейнеров
- [ ] Оптимизировать Dockerfile для production

### 9.2. Финальное тестирование
- [ ] Smoke тесты всей системы с нуля
- [ ] Тестирование интеграции со всеми сервисами
- [ ] Валидация соответствия всем требованиям ТЗ

---

> **Статус проекта**: 🔴 **НЕ НАЧАТ** - Требуется полная переработка существующего кода согласно данному чек-листу и техническому заданию. 