# CHECK LIST: Разработка Multi-Platform Parser Service

> **Этот файл — подробный чек-лист разработки мультиплатформенного микросервиса parsing-service. Сервис будет поддерживать парсинг данных из различных социальных платформ (Telegram, Instagram, WhatsApp и др.) через модульную систему адаптеров. Phase 1 фокусируется на Telegram согласно техническому заданию.**

## ЭТАП 1: Подготовка мультиплатформенной архитектуры

### 1.1. Анализ и переработка архитектуры
- [ ] Проанализировать существующий код parsing-service
- [ ] Создать план миграции к мультиплатформенной архитектуре
- [ ] Спроектировать абстрактную систему Platform Adapters
- [ ] Определить универсальные модели данных (platform-agnostic)
- [ ] Спроектировать API endpoints с параметром platform
- [ ] Создать архитектуру plugin-системы для новых платформ

### 1.2. Настройка универсальной базы данных PostgreSQL
- [ ] Создать отдельную БД для parsing-service (parsing_db)
- [ ] Настроить пользователя parsing_user с необходимыми правами
- [ ] Обновить строку подключения в docker-compose.yml
- [ ] Создать универсальные модели SQLAlchemy:
  - [ ] ParseTask (с полем platform: telegram/instagram/whatsapp)
  - [ ] ParseResult (универсальная структура + platform_specific_data JSON)
  - [ ] PlatformChat (обобщенная информация о чатах/группах/страницах)
  - [ ] PlatformUser (унифицированные данные пользователей)
  - [ ] ParseLog (логи с указанием платформы)

### 1.3. Интеграция с RabbitMQ (мультиплатформенные очереди)
- [ ] Настроить Celery для работы с RabbitMQ
- [ ] Создать очереди для разных платформ (telegram_queue, instagram_queue, whatsapp_queue)
- [ ] Создать очереди для разных приоритетов (low, normal, high) для каждой платформы
- [ ] Реализовать универсальную структуру задач:
  - [ ] user_id, link, platform, type, account_id, resume_point, status

### 1.4. Интеграция с Redis (состояния с namespacing)
- [ ] Настроить подключение к Redis для хранения состояний
- [ ] Реализовать класс для управления состояниями задач с platform namespacing
- [ ] Создать систему хранения FloodWait/Rate limit таймеров для всех платформ
- [ ] Настроить TTL для различных типов данных по платформам

## ЭТАП 2: Интеграция с существующими сервисами (мультиплатформенная)

### 2.1. Интеграция с Integration Service (все платформы)
- [ ] Изучить API Integration Service для получения аккаунтов всех платформ
- [ ] Реализовать HTTP клиент для взаимодействия с Integration Service
- [ ] Создать функции для получения аккаунтов с фильтрацией по platform:
  - [ ] Telegram аккаунты (phase 1)
  - [ ] Instagram аккаунты (планируется)
  - [ ] WhatsApp аккаунты (планируется)
- [ ] Реализовать алгоритм выбора оптимального аккаунта с учетом платформы

### 2.2. Интеграция с Vault (мультиплатформенные секреты)
- [ ] Настроить VaultClient с AppRole аутентификацией
- [ ] Реализовать получение секретов для всех платформ:
  - [ ] Telegram .session файлы и api_id/api_hash
  - [ ] Instagram API токены (планируется)
  - [ ] WhatsApp Business API токены (планируется)
- [ ] Создать функции для безопасного создания временных файлов/токенов
- [ ] Настроить пути в Vault: `kv/integrations/{platform}/sessions/{session_id}`

### 2.3. Интеграция с API Gateway (универсальная)
- [ ] Настроить JWT аутентификацию для parsing endpoints
- [ ] Реализовать middleware для извлечения user_id из JWT токена
- [ ] Создать декораторы для проверки прав доступа
- [ ] Добавить валидацию параметра platform в запросах

## ЭТАП 3: Реализация мультиплатформенных API endpoints

### 3.1. Endpoint добавления задач парсинга (универсальный)
- [ ] **POST /parser/queue** - основной endpoint с параметром platform
- [ ] Реализовать Pydantic схемы для валидации:
  - [ ] Универсальная схема ParseTaskCreate с полем platform
  - [ ] Platform-specific валидация (Telegram, Instagram, WhatsApp)
- [ ] Добавить валидацию ссылок для каждой платформы:
  - [ ] Telegram: t.me/username, @username
  - [ ] Instagram: instagram.com/username (планируется)
  - [ ] WhatsApp: wa.me/groupid (планируется)
- [ ] Реализовать автоопределение типа в зависимости от платформы
- [ ] Добавить роутинг задач в соответствующие очереди платформ

### 3.2. Endpoints управления задачами (с фильтрацией по платформе)
- [ ] **GET /parser/tasks?platform=telegram** - список задач с фильтром по платформе
- [ ] **GET /parser/tasks/{task_id}** - информация о конкретной задаче
- [ ] **POST /parser/tasks/{task_id}/pause** - поставить задачу на паузу
- [ ] **POST /parser/tasks/{task_id}/resume** - возобновить задачу
- [ ] **DELETE /parser/tasks/{task_id}** - удалить задачу
- [ ] Добавить фильтрацию по статусу, дате, типу, платформе
- [ ] Реализовать пагинацию для больших списков

### 3.3. Endpoint поиска сообществ (мультиплатформенный)
- [ ] **GET /parser/search?platform=telegram&q=keywords** - поиск с указанием платформы
- [ ] Реализовать параметры: platform, q (query), offset, limit
- [ ] Интегрировать с Platform Adapters:
  - [ ] TelegramAdapter для поиска публичных чатов
  - [ ] InstagramAdapter (планируется)
  - [ ] WhatsAppAdapter (планируется)
- [ ] Унифицированный формат ответа для всех платформ
- [ ] Кэшировать результаты поиска с platform namespacing

### 3.4. Endpoint выгрузки результатов (универсальный)
- [ ] **GET /parser/result/{task_id}?format=json&platform_filter=telegram** - получение результатов
- [ ] Реализовать поддержку форматов: JSON, CSV, NDJSON
- [ ] Создать универсальную структуру данных:
  - [ ] Общие поля: platform, platform_id, username, display_name
  - [ ] Platform-specific поля в JSON объекте
- [ ] Добавить фильтрацию результатов по платформе
- [ ] Реализовать streaming для больших файлов

## ЭТАП 4: Создание системы Platform Adapters (начало с Telegram)

### 4.1. Базовая архитектура Platform Adapters
- [ ] Создать абстрактный базовый класс `BasePlatformAdapter`
- [ ] Определить общие методы: parse(), search(), get_account_info()
- [ ] Реализовать Factory pattern для создания адаптеров
- [ ] Создать систему регистрации новых адаптеров платформ
- [ ] Настроить конфигурацию для каждой платформы

### 4.2. TelegramAdapter - Phase 1 (полная реализация)
- [ ] Установить Telethon в requirements.txt (версия 1.34.0+)
- [ ] Создать класс TelegramAdapter наследующий BasePlatformAdapter
- [ ] Реализовать TelegramClient wrapper с обработкой ошибок
- [ ] Настроить создание клиента из .session файла через Vault

### 4.3. Telegram парсинг групп (iter_participants)
- [ ] Реализовать метод parse_group() в TelegramAdapter
- [ ] Извлекать данные: user_id, username, full_name, language_code, status
- [ ] Добавить получение join_date (если доступно)
- [ ] Реализовать постраничное получение участников
- [ ] Сохранять результаты в универсальном формате

### 4.4. Telegram парсинг каналов (get_messages)
- [ ] Реализовать метод parse_channel() в TelegramAdapter
- [ ] Парсинг сообщений из каналов
- [ ] Получать комментарии к сообщениям (если включены)
- [ ] Извлекать информацию о пользователях-комментаторах
- [ ] Добавить ограничение глубины (10,000 сообщений)

### 4.5. Telegram общая информация и поиск
- [ ] Реализовать метод get_chat_info() для метаданных
- [ ] Обработать различные типы чатов (супергруппы, каналы)
- [ ] Реализовать метод search_communities() для поиска
- [ ] Сохранять информацию в универсальные таблицы с platform='telegram'

### 4.6. Подготовка для будущих адаптеров
- [ ] Создать заглушки InstagramAdapter и WhatsAppAdapter
- [ ] Документировать интерфейс для новых адаптеров
- [ ] Настроить plugin систему для динамической загрузки адаптеров

## ЭТАП 5: Обработка ошибок и лимитов Telegram

### 5.1. Обработка Telegram API ошибок
- [ ] FloodWaitError - сохранение времени ожидания в Redis
- [ ] SessionExpiredError - пометка сессии как невалидной
- [ ] AuthKeyError - обработка проблем с ключом авторизации
- [ ] ChannelPrivateError - пропуск приватных каналов

### 5.2. Rate limiting и адаптивные паузы
- [ ] Реализовать счетчик запросов (200-300 без задержки)
- [ ] Добавить адаптивную паузу после превышения лимита
- [ ] Настроить безопасный лимит: 100 сообщений/сек

### 5.3. Resume functionality (восстановление задач)
- [ ] Сохранять offset_id и message_id в Redis
- [ ] Реализовать восстановление с последней позиции
- [ ] Обновлять прогресс задачи в реальном времени

## ЭТАП 6: Celery Worker и асинхронная обработка

### 6.1. Реализация Celery задач
- [ ] Создать основную задачу parse_telegram_chat
- [ ] Реализовать задачи для разных типов парсинга
- [ ] Добавить retry логику с экспоненциальным backoff

### 6.2. Управление аккаунтами в воркерах
- [ ] Реализовать алгоритм выбора аккаунта в задаче
- [ ] Добавить переключение аккаунтов при ban/flood
- [ ] Обновлять статус аккаунта в Integration Service

## ЭТАП 7: Безопасность и мониторинг

### 7.1. Безопасность и защита данных
- [ ] Все .session файлы только через Vault API
- [ ] Удаление временных файлов после использования
- [ ] Шифрование чувствительных данных в БД

### 7.2. Интеграция с мониторингом
- [ ] Добавить Prometheus метрики
- [ ] Настроить алерты в Alertmanager
- [ ] Создать Grafana дашборд для parsing-service

## ЭТАП 8: Тестирование и оптимизация

### 8.1. Unit тесты
- [ ] Написать тесты для всех основных функций
- [ ] Тесты для API endpoints с mock данными
- [ ] Тесты для Telegram парсинга с фиктивными клиентами

### 8.2. Интеграционные тесты
- [ ] Тесты взаимодействия с Integration Service
- [ ] Тесты работы с Vault (получение секретов)
- [ ] Тесты полного цикла: создание задачи → парсинг → результат

## ЭТАП 9: Деплой и production готовность

### 9.1. Подготовка к production
- [ ] Обновить docker-compose.yml для всех компонентов
- [ ] Настроить health checks для всех контейнеров
- [ ] Оптимизировать Dockerfile для production

### 9.2. Финальное тестирование
- [ ] Smoke тесты всей системы с нуля
- [ ] Тестирование интеграции со всеми сервисами
- [ ] Валидация соответствия всем требованиям ТЗ

---

> **Статус проекта**: 🔴 **НЕ НАЧАТ** - Требуется полная переработка существующего кода согласно данному чек-листу и техническому заданию. 