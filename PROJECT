# PROJECT — Полное описание проекта

> **Этот файл — основное описание проекта. Здесь всегда хранится актуальное, максимально подробное описание архитектуры, сервисов, инфраструктуры, статуса и принципов работы. Любой новый участник может ознакомиться с этим файлом и сразу понять, как устроен проект, что реализовано, а что ещё нет. Все изменения должны своевременно отражаться здесь.**
> 
> **ВАЖНО: При обновлении этого файла НИКОГДА НЕ УДАЛЯТЬ существующую актуальную информацию и НЕ МЕНЯТЬ структуру файла. Только обновлять неактуальную информацию и добавлять новую.**

## Назначение
SaaS-платформа для автоматизации маркетинга, генерации контента и мультиканальных воронок.

## Архитектура
- Микросервисная архитектура
- Каждый сервис — отдельный контейнер
- Взаимодействие через API Gateway и backend-сеть
- Все сервисы и инфраструктурные компоненты работают в Docker Compose

## Технологии
- Python (FastAPI)
- MySQL (основная БД)
- PostgreSQL (для интеграций)
- Redis
- RabbitMQ
- Nginx
- Prometheus
- Grafana
- Vault
- Elasticsearch
- Kibana
- Logstash
- Docker Compose

## Инфраструктура
- ✅ Docker Compose настроен и работает
- ✅ Единая сеть backend для всех сервисов
- ✅ Volume для хранения данных (MySQL, PostgreSQL, Redis, RabbitMQ, Elasticsearch, Vault)
- ✅ Все базовые сервисы (MySQL, PostgreSQL, Redis, RabbitMQ, Vault, Prometheus, Grafana, ELK) работают и доступны
- ✅ Все volumes и сети корректно проброшены
- ✅ Нет лишних открытых портов наружу
- ⚠️ Админские сервисы (Grafana, Prometheus, Kibana, Alertmanager, Vault) доступны только из внутренней docker-сети или через SSH-туннель. Наружу открыты только 80 и 443 для публичных сервисов (API Gateway, фронт).

## База данных
- ✅ MySQL запущен и доступен на порту 3307
- ✅ Создана база данных integration_service
- ✅ Настроен пользователь telegraminvi с необходимыми правами
- ✅ PostgreSQL для Integration Service запущен и доступен на порту 5433
- ✅ База данных integration_db создана и полностью инициализирована
- ✅ Пользователь integration_user настроен с полными правами
- ✅ Схема БД Integration Service создана (4 таблицы с индексами и триггерами)
- ❌ Остальные базы данных для сервисов ещё не созданы
- ❌ Не настроены миграции и схемы баз данных для других сервисов

## ELK Stack (Elasticsearch, Logstash, Kibana)
- ✅ Elasticsearch запущен, доступен на порту 9200, индексы создаются корректно
- ✅ Logstash запущен, читает логи из /var/www/html/logs/services/ и /var/www/html/logs/api-gateway/ (volume проброшен абсолютным путём)
- ✅ Тестовые логи обработаны, индекс logs-YYYY.MM.DD появляется в Elasticsearch
- ✅ Документы содержат поля: @timestamp, level, message, type и др.
- ⚠️ Kibana: index pattern logs-* создаётся, но поле Timestamp field неактивно (вечная загрузка) — будет решено после появления реальных логов
- ⚠️ Визуализации и дашборды будут настраиваться после поступления реальных логов

## Мониторинг
- ✅ Prometheus запущен (только во внутренней сети)
- ✅ Grafana запущена (только во внутренней сети)
- ✅ Grafana и Prometheus находятся в одной docker-сети, интеграция подтверждена
- ✅ Grafana успешно видит Prometheus по адресу http://prometheus:9090
- ✅ Метрики с MySQL, RabbitMQ, Redis, а также с backend-сервисов собираются (экспортеры работают)
- ⚠️ Для доступа к Grafana, Prometheus, Kibana, Alertmanager используйте SSH-туннель
- ❌ Не настроены пользовательские дашборды в Grafana (можно создавать)

## Сервисы
- ✅ API Gateway запущен и доступен на порту 8000
- ✅ Integration Service запущен и полностью функционален (порт 8001)
- ✅ User Service запущен и работает
- ❌ Остальные микросервисы (Billing, Scenario, Content, Invite, Parsing) ещё не протестированы
- ❌ Не настроено взаимодействие между сервисами
- ❌ Не протестированы API эндпоинты остальных сервисов

## Безопасность
- ✅ Vault запущен в production режиме с файловым хранением (только во внутренней сети)
- ✅ Настроены unseal keys и инициализация для Vault
- ✅ Данные Vault сохраняются при перезагрузке (volume vault_data:/vault/data)
- ✅ Проброс портов для админских сервисов убран, доступ только через внутреннюю сеть или SSH-туннель
- ✅ Integration Service полностью интегрирован с Vault для хранения секретов
- ✅ API Gateway интегрирован с Vault (CSRF_SECRET_KEY, JWT_SECRET_KEY)
- ✅ HTTPS настроен и работает через Let's Encrypt
- ✅ GitHub push protection: секреты не попадают в репозиторий, токены в переменных окружения
- ❌ Не настроено хранение секретов в Vault для остальных сервисов
- ❌ Не настроен firewall

## Очереди и кэширование
- ✅ Redis запущен и доступен на порту 6380
- ✅ RabbitMQ запущен и доступен на портах 5672, 15672, 15692
- ❌ Не настроены очереди в RabbitMQ
- ❌ Не настроено кэширование в Redis

## Доступы
- API Gateway: http://92.113.146.148:8000 (будет http/https, публично)
- Integration Service: только через SSH-туннель (локально http://localhost:8001)
- Grafana: только через SSH-туннель (локально http://localhost:3000)
- Kibana: только через SSH-туннель (локально http://localhost:5601)
- Prometheus: только через SSH-туннель (локально http://localhost:9090)
- Alertmanager: только через SSH-туннель (локально http://localhost:9093)
- RabbitMQ: http://92.113.146.148:15672 (user/password)
- MySQL root: root/Lfnm97HnPug8
- MySQL user: telegraminvi/szkTgBhWh6XU
- PostgreSQL integration_user: integration_user/integration_password
- Vault: только через SSH-туннель (локально http://localhost:8201, root token)

### Безопасность и доступ к админским сервисам
- Все админские сервисы (Grafana, Prometheus, Alertmanager, Kibana, Vault, RabbitMQ Management, Logstash Monitoring, Elasticsearch) проброшены только на 127.0.0.1 сервера.
- Доступ к ним возможен только через SSH-туннель.
- Наружу открыты только порты 80 и 443.
- Админские интерфейсы полностью изолированы от внешнего мира.

## Внешний reverse proxy (nginx)
- Для публикации приложения на домене content-factory.xyz используется отдельный сервис nginx в docker-compose.
- Nginx слушает порты 80 и 443, проксирует все запросы на сервис api-gateway (порт 8000).
- Конфиг nginx поддерживает работу Let's Encrypt (автоматический выпуск HTTPS-сертификатов).
- Вся внешняя маршрутизация и SSL-терминация происходит на уровне этого nginx.
- Внутри контейнера api-gateway также используется nginx, но только для внутренних нужд (например, проксирование к integration-service).
- Внешний доступ к приложению осуществляется только через nginx по адресу http://content-factory.xyz (и в будущем https://content-factory.xyz).

### HTTPS и безопасность
- Домен content-factory.xyz обслуживается через nginx с поддержкой HTTPS (Let's Encrypt).
- Сертификаты выпускаются и продлеваются с помощью certbot (docker-compose).
- Для автоматического продления сертификата используется команда: docker-compose run --rm certbot renew && docker-compose restart nginx (рекомендуется добавить в cron).
- nginx автоматически редиректит все http-запросы на https.
- Вся внешняя маршрутизация и SSL-терминация происходит на уровне nginx.

### Централизованное хранение секретов (Vault)
- Все чувствительные данные (пароли, токены, ключи, CSRF/JWT secret) выносятся в HashiCorp Vault.
- API Gateway получает CSRF_SECRET_KEY и JWT_SECRET_KEY из Vault, .env не содержит секретов в открытом виде.
- Интеграция с Vault реализована для API Gateway, Integration Service и постепенно внедряется для остальных сервисов.
- Структура хранения: secret/<service>/<ключ> (например, secret/mysql/root_password, secret/user-service/secret_key).
- Пример записи секрета:
  vault kv put secret/mysql root_password=Lfnm97HnPug8 user=telegraminvi user_password=szkTgBhWh6XU
- Пример получения секрета в Python:
  import hvac
  client = hvac.Client(url='http://vault:8201', token='root')
  secret = client.secrets.kv.v2.read_secret_version(path='mysql')
  print(secret['data']['data']['root_password'])
- Постепенно все сервисы будут получать секреты из Vault, а не из .env/docker-compose.
- В docker-compose и .env останутся только VAULT_ADDR и VAULT_TOKEN.

### Планы по фронтенду
1. Первый фронт — админка:
   - Мониторинг пользователей (список, фильтры, поиск)
   - Просмотр расходов, оплат, баланса по пользователям
   - Управление пользователями (блокировка, лимиты)
   - Дашборды по метрикам (интеграция с Grafana через iframe или API)
   - Просмотр логов (интеграция с Kibana или отдельный UI)
   - Управление тарифами, настройками, интеграциями
   - Доступ только по https, авторизация только для админов (JWT/OAuth2)
   - Все чувствительные данные — только через Vault
   - Логи действий админов (audit trail)
2. Второй фронт — пользовательский аккаунт:
   - Регистрация пользователя (email, телефон, соцсети)
   - Вход/выход, восстановление пароля
   - Личный кабинет: профиль, тариф, история оплат, настройки интеграций
   - Просмотр и управление своими расходами, лимитами, балансом
   - Интеграция с backend API (через API Gateway)
   - HTTPS, защита от CSRF, rate limiting, 2FA (по желанию)
   - **Лендинг реализован, все секции (описание, преимущества, тарифы, FAQ, форма обратной связи) и SEO-теги работают, фронт деплоится через volume frontend-static и nginx.**
   - **Лендинг полностью адаптивен, протестирован на всех устройствах, нет горизонтального скролла, визуал и UX доработаны для мобильных и планшетов.**

#### Архитектурные рекомендации
- Фронтенды как отдельные docker-сервисы (SPA: React/Vue/Svelte)
- API Gateway — единственная точка входа для всех фронтов
- JWT-авторизация (разные роли: admin, user), секреты для подписи токенов — только через Vault
- Мониторинг: интеграция с Grafana/Kibana через iframe или API (для админки)
- Документация API: Swagger/OpenAPI, доступен только авторизованным
- Все секреты — только через Vault, HTTPS для всех фронтов, логи действий

- Swagger UI и ReDoc отключены во внешней среде (docs_url, redoc_url = None), доступны только при DEBUG=true.
- OpenAPI JSON (/openapi.json) остаётся доступен для интеграций.
- Логирование (audit trail) теперь реализовано для login, logout, register, ошибок аутентификации. Все логи в формате JSON для Logstash/ELK.
- Security схемы (JWT, CSRF) описаны в OpenAPI/Swagger.

- Для /auth/login и /auth/register реализована строгая валидация входных данных по pydantic-схемам, ошибки валидации логируются, OpenAPI обновляется автоматически.

- Volume frontend-static для фронта теперь не анонимный, а локальная папка (./frontend-static:/usr/share/nginx/html:ro). Всё содержимое этой папки автоматически доступно nginx и на https://content-factory.xyz/.

- ✅ Интеграция auth (регистрация и логин) через API Gateway завершена, все критические ошибки устранены
- ✅ После регистрации на фронте автоматически выполняется логин, токены сохраняются, происходит редирект на /dashboard
- ✅ Регистрация и автоматический логин работают через api-gateway, интеграция auth завершена
- ⏳ Следующий шаг: добавить капчу на регистрацию и email-валидацию

### Пользовательский кабинет (Dashboard)
- Sidebar (левое меню) реализован как отдельный компонент
- На desktop Sidebar всегда открыт, на мобильных скрывается и открывается по кнопке-гамбургеру в Header
- Для мобильных реализован overlay (затемнение фона) и крестик для закрытия меню
- После выбора пункта меню Sidebar автоматически закрывается на мобильных
- Используются Tailwind, SVG-иконки, поддержка светлой/тёмной темы
- Вся навигация и адаптивность реализованы через состояние React и Tailwind-классы, без прямого обращения к window.innerWidth в JSX
- **В текущей версии проекта роли пользователей не реализованы. После внедрения ролей потребуется реализовать и протестировать отображение Dashboard для разных ролей.**

---

## Текущие сервисы и контейнеры

### 1. Prometheus
- **Назначение:** Сбор метрик со всех сервисов, инфраструктуры, экспортёров.
- **Внутренний адрес:** prometheus:9090 (docker-сеть backend)
- **Внешний адрес:** Только через SSH-туннель: http://localhost:9090
- **Данные:** ./prometheus:/etc/prometheus (volume)
- **Команды:**
  - Перезапуск: `docker-compose restart prometheus`
  - Логи: `docker-compose logs prometheus --tail 100`
  - Войти в контейнер: `docker-compose exec prometheus sh`
- **Особенности:**
  - Конфиг prometheus.yml настраивает источники метрик
  - Метрики доступны только из внутренней сети

### 2. Grafana
- **Назначение:** Визуализация метрик, дашборды, алерты
- **Внутренний адрес:** grafana:3000
- **Внешний адрес:** Только через SSH-туннель: http://localhost:3000
- **Данные:** ./grafana:/var/lib/grafana (volume)
- **Команды:**
  - Перезапуск: `docker-compose restart grafana`
  - Логи: `docker-compose logs grafana --tail 100`
  - Войти в контейнер: `docker-compose exec grafana sh`
- **Особенности:**
  - Дефолтный логин: admin/admin (сменить после первого входа)
  - Дашборды и источники данных сохраняются в volume

### 3. Kibana
- **Назначение:** Визуализация логов из Elasticsearch
- **Внутренний адрес:** kibana:5601
- **Внешний адрес:** Только через SSH-туннель: http://localhost:5601
- **Команды:**
  - Перезапуск: `docker-compose restart kibana`
  - Логи: `docker-compose logs kibana --tail 100`
  - Войти в контейнер: `docker-compose exec kibana sh`
- **Особенности:**
  - Требует индекс logs-* в Elasticsearch

### 4. Elasticsearch
- **Назначение:** Хранение логов, поиск, аналитика
- **Внутренний адрес:** elasticsearch:9200
- **Внешний адрес:** Только через SSH-туннель: http://localhost:9200
- **Данные:** ./elasticsearch:/usr/share/elasticsearch/data (volume)
- **Команды:**
  - Перезапуск: `docker-compose restart elasticsearch`
  - Логи: `docker-compose logs elasticsearch --tail 100`
  - Войти в контейнер: `docker-compose exec elasticsearch sh`
- **Особенности:**
  - Требует много памяти (рекомендуется 2ГБ+)

### 5. Logstash
- **Назначение:** Парсинг и обработка логов, отправка в Elasticsearch
- **Внутренний адрес:** logstash:5044
- **Данные:** ./logstash:/usr/share/logstash/pipeline (volume)
- **Команды:**
  - Перезапуск: `docker-compose restart logstash`
  - Логи: `docker-compose logs logstash --tail 100`
  - Войти в контейнер: `docker-compose exec logstash sh`
- **Особенности:**
  - Конфиг logstash.conf настраивает парсинг логов

### 6. Alertmanager
- **Назначение:** Алерты по метрикам Prometheus
- **Внутренний адрес:** alertmanager:9093
- **Внешний адрес:** Только через SSH-туннель: http://localhost:9093
- **Команды:**
  - Перезапуск: `docker-compose restart alertmanager`
  - Логи: `docker-compose logs alertmanager --tail 100`
  - Войти в контейнер: `docker-compose exec alertmanager sh`

### 7. MySQL
- **Назначение:** Основная база данных для сервисов
- **Внутренний адрес:** mysql:3306
- **Внешний адрес:** Только через SSH-туннель: localhost:3307
- **Данные:** ./mysql:/var/lib/mysql (volume)
- **Пользователи:**
  - root/Lfnm97HnPug8
  - telegraminvi/szkTgBhWh6XU
- **Команды:**
  - Перезапуск: `docker-compose restart mysql`
  - Логи: `docker-compose logs mysql --tail 100`
  - Войти в контейнер: `docker-compose exec mysql bash`
  - MySQL shell: `docker-compose exec mysql mysql -u root -p`

### 8. Redis
- **Назначение:** Кэш, очереди, хранение refresh token
- **Внутренний адрес:** redis:6379
- **Внешний адрес:** Только через SSH-туннель: localhost:6380
- **Данные:** ./redis:/data (volume)
- **Команды:**
  - Перезапуск: `docker-compose restart redis`
  - Логи: `docker-compose logs redis --tail 100`
  - Войти в контейнер: `docker-compose exec redis sh`
  - Redis CLI: `docker-compose exec redis redis-cli`

### 9. RabbitMQ
- **Назначение:** Очереди задач между сервисами
- **Внутренний адрес:** rabbitmq:5672
- **Внешний адрес:** Только через SSH-туннель: http://localhost:15672 (UI)
- **Данные:** ./rabbitmq:/var/lib/rabbitmq (volume)
- **Команды:**
  - Перезапуск: `docker-compose restart rabbitmq`
  - Логи: `docker-compose logs rabbitmq --tail 100`
  - Войти в контейнер: `docker-compose exec rabbitmq bash`
- **Особенности:**
  - UI: http://localhost:15672 (user/password)

### 10. Vault
- **Назначение:** Хранение секретов, токенов, ключей
- **Внутренний адрес:** vault:8201
- **Внешний адрес:** Только через SSH-туннель: http://localhost:8201
- **Данные:** vault_data:/vault/data (персистентный volume)
- **Команды:**
  - Перезапуск: `docker-compose restart vault`
  - Логи: `docker-compose logs vault --tail 100`
  - Войти в контейнер: `docker-compose exec vault sh`
  - ~~Разблокировка: `docker-compose exec vault vault operator unseal`~~ **БОЛЬШЕ НЕ ТРЕБУЕТСЯ**
- **Особенности:**
  - **✅ Production режим с файловым хранением (storage "file")**
  - **✅ Данные сохраняются при перезагрузке контейнера**
  - **✅ Инициализация и unseal keys настроены**
  - **✅ Root token безопасно хранится в переменных окружения**
  - **✅ KV v2 secrets engine для хранения секретов интеграций**
  - **✅ АВТОМАТИЧЕСКИЙ UNSEALING через Vault Unsealer Service**
  - **✅ Self-healing: автоматическое восстановление от sealed state**
  - **✅ Enhanced health checks с проверкой unsealed статуса**
  - Все секреты для сервисов хранятся здесь
  - Интеграция с Integration Service и API Gateway полностью работает

### 10a. Vault Unsealer Service (vault-unsealer)
- **Назначение:** Автоматический unsealing HashiCorp Vault при запуске и мониторинг 24/7
- **Внутренний адрес:** vault-unsealer (сервисный контейнер)
- **Зависимости:** vault (ждёт запуска Vault)
- **Команды:**
  - Перезапуск: `docker-compose restart vault-unsealer`
  - Логи: `docker-compose logs vault-unsealer --tail 100`
  - Тестовый режим: `UNSEALER_TEST_MODE=true docker-compose up vault vault-unsealer`
- **Конфигурация (.env):**
  ```bash
  VAULT_UNSEAL_KEY_1=your-first-unseal-key
  VAULT_UNSEAL_KEY_2=your-second-unseal-key  
  VAULT_UNSEAL_KEY_3=your-third-unseal-key
  UNSEALER_MAX_RETRIES=100
  UNSEALER_RETRY_DELAY=3
  UNSEALER_MONITOR_INTERVAL=30
  UNSEALER_LOG_LEVEL=DEBUG
  ```
- **Возможности:**
  - **🔄 Automatic Unsealing:** Vault автоматически разблокируется при каждом запуске
  - **🔍 Continuous Monitoring:** Проверка статуса каждые 30 секунд
  - **🩹 Self-Healing:** Автоматический re-unseal если Vault запечатается
  - **📋 Structured Logging:** Детальные логи с timestamp и цветной индикацией
  - **🔐 Security Compliant:** Unseal keys только в переменных окружения (не в логах)
  - **⚡ Production Ready:** Retry logic, error handling, graceful shutdown
  - **🧪 Test Mode:** Диагностический режим для отладки проблем
- **Логи успешной работы:**
  ```
  [2025-06-09] INFO:  🚀 Vault Unsealer Service starting up
  [2025-06-09] INFO:  Found 3 unseal keys
  [2025-06-09] INFO:  Vault is reachable (attempt 1/100)
  [2025-06-09] INFO:  Current unseal progress: 0/3
  [2025-06-09] INFO:  Unseal progress: 1/3
  [2025-06-09] INFO:  Unseal progress: 2/3
  [2025-06-09] INFO:  Unseal progress: 0/3  ← sealed:false
  [2025-06-09] INFO:  ✅ Vault successfully unsealed!
  [2025-06-09] INFO:  Starting continuous Vault monitoring (interval: 30s)
  [2025-06-09] DEBUG: 🔓 Vault status: unsealed
  ```
- **Архитектура:**
  - **Alpine Linux** контейнер с minimal dependencies (bash, curl, jq)
  - **Non-root user** для безопасности
  - **Health checks** интеграция с Docker Compose
  - **Environment validation** проверка наличия минимум 3 ключей
  - **Progressive unsealing** с real-time отображением прогресса
  - **Graceful shutdown** с обработкой SIGTERM/SIGINT
- **Production Impact:**
  - **✅ Zero Manual Intervention:** Проект полностью автономен после перезапусков
  - **✅ Операционная готовность:** Vault никогда не остается sealed
  - **✅ Monitoring Integration:** Structured logs для ELK/Prometheus
  - **✅ Security Compliance:** No key exposure, minimal permissions

### 11. API Gateway (api-gateway)
- **Назначение:** Единая точка входа для всех фронтов и сервисов, проксирование, аутентификация, лимиты, CSRF, логирование
- **Внутренний адрес:** api-gateway:8000
- **Внешний адрес:** http://92.113.146.148:8000 (или через nginx)
- **Команды:**
  - Перезапуск: `docker-compose restart api-gateway`
  - Логи: `docker-compose logs api-gateway --tail 100`
  - Войти в контейнер: `docker-compose exec api-gateway sh`
- **Особенности:**
  - Все запросы с фронта идут через этот сервис
  - Лимиты через slowapi, логирование в stdout (JSON)
  - Секреты (CSRF, JWT) берутся из Vault

### 12. User Service (user-service)
- **Назначение:** Регистрация, логин, управление пользователями
- **Внутренний адрес:** user-service:8001
- **Команды:**
  - Перезапуск: `docker-compose restart user-service`
  - Логи: `docker-compose logs user-service --tail 100`
  - Войти в контейнер: `docker-compose exec user-service sh`
- **Особенности:**
  - Работает только через api-gateway
  - Подключается к MySQL (user_service)

### 13. Integration Service (integration-service)
- **Назначение:** Полнофункциональный микросервис для управления интеграциями с внешними платформами (Telegram API)
- **Внутренний адрес:** integration-service:8000
- **Внешний адрес:** Только через SSH-туннель: http://localhost:8001
- **База данных:** integration-postgres:5432 (PostgreSQL)
- **Команды:**
  - Перезапуск: `docker-compose restart integration-service`
  - Логи: `docker-compose logs integration-service | tail 100`
  - Войти в контейнер: `docker-compose exec integration-service sh`
- **Особенности:**
  - Полностью асинхронный FastAPI с PostgreSQL
  - Интеграция с Vault для секретов
  - Health checks и мониторинг готовности
  - Rate limiting и система логирования
  - Prometheus метрики включены
  - **✅ Telegram интеграция полностью работает: SMS коды приходят в приложение, аккаунты подключаются успешно**
  - **✅ Telethon 1.34.0 с исправленной логикой клиента (не отключается между отправкой и подтверждением кода)**
  - **✅ Автоматическое переподключение при потере соединения**
  - **✅ Audit trail всех операций интеграций**
  - **Статус: ✅ PRODUCTION READY - готов к эксплуатации**

### 14. Frontend
- **Назначение:** Внешний SPA (React)
- **Внутренний адрес:** frontend:3000 (dev), статика деплоится в ./frontend-static
- **Внешний адрес:** https://content-factory.xyz
- **Данные:** ./frontend-static:/usr/share/nginx/html:ro (volume)
- **Команды:**
  - Сборка: `cd frontend && npm run build`
  - Перезапуск nginx: `docker-compose restart nginx`
- **Особенности:**
  - Все статика деплоится через volume
  - Для разработки: `npm run dev` (порт 3000)

### 15. Nginx (reverse proxy)
- **Назначение:** Внешний reverse proxy, SSL-терминация, публикация фронта и API
- **Внутренний адрес:** nginx:80, nginx:443
- **Внешний адрес:** http://content-factory.xyz, https://content-factory.xyz
- **Данные:** ./nginx.conf, ./frontend-static
- **Команды:**
  - Перезапуск: `docker-compose restart nginx`
  - Логи: `docker-compose logs nginx --tail 100`
  - Войти в контейнер: `docker-compose exec nginx sh`
- **Особенности:**
  - SSL через Let's Encrypt
  - Проксирует все запросы на api-gateway и frontend

### 16. PostgreSQL Integration (integration-postgres)
- **Назначение:** База данных для Integration Service
- **Внутренний адрес:** integration-postgres:5432
- **Внешний адрес:** Только через SSH-туннель: localhost:5433
- **Данные:** ./integration_postgres_data:/var/lib/postgresql/data (volume)
- **Пользователи:**
  - integration_user/integration_password
- **Команды:**
  - Перезапуск: `docker-compose restart integration-postgres`
  - Логи: `docker-compose logs integration-postgres | tail 100`
  - Войти в контейнер: `docker-compose exec integration-postgres bash`
  - PostgreSQL shell: `docker-compose exec integration-postgres psql -U integration_user -d integration_db`
- **Особенности:**
  - PostgreSQL 15 с поддержкой JSONB, UUID, индексов
  - 4 таблицы: telegram_sessions, telegram_bots, telegram_channels, integration_logs
  - Автоматические триггеры для updated_at
  - Полнотекстовый поиск и GIN индексы

---

## Критические обновления (2025-06-04)

### ✅ VAULT ПЕРЕВЕДЕН В PRODUCTION РЕЖИМ
**Решена критическая проблема с потерей данных при перезагрузке:**
- **Production конфигурация:** Vault теперь использует файловое хранение (`storage "file"`) вместо dev-режима
- **Персистентные данные:** Volume `vault_data:/vault/data` обеспечивает сохранность всех секретов
- **Безопасная инициализация:** Настроена корректная инициализация с unseal ключами
- **Защита токенов:** Root token вынесен в переменные окружения (`VAULT_ROOT_TOKEN`)
- **Права доступа:** Исправлены права `vault:vault` для корректной работы файлового backend
- **GitHub Protection:** Токены больше не попадают в репозиторий благодаря push protection

### ✅ TELEGRAM ИНТЕГРАЦИЯ ПОЛНОСТЬЮ РАБОТАЕТ
**Решены все проблемы с подключением аккаунтов и доставкой кодов:**
- **SMS коды доставляются:** Коды приходят в приложение Telegram (`Code type: SentCodeTypeApp`)
- **Аккаунты подключаются:** Успешно создаются `TelegramSession` записи в базе данных
- **Клиент остается подключенным:** Исправлена логика - клиент не отключается между отправкой и подтверждением кода
- **Автоматическое переподключение:** При потере соединения клиент автоматически переподключается
- **Telethon 1.34.0:** Обновлена библиотека, убраны deprecated параметры (`force_sms`, `allow_flashcall`)
- **Vault интеграция:** Telegram API ключи безопасно хранятся в Vault и корректно извлекаются

### ✅ БЕЗОПАСНОСТЬ И ОПЕРАЦИОННАЯ ГОТОВНОСТЬ
**Достигнут production уровень безопасности:**
- **Encrypted Sessions:** Сессии Telegram шифруются через Vault Transit engine
- **Audit Trail:** Все операции интеграций логируются с полной детализацией
- **Rate Limiting:** Защита от flood-атак и злоупотреблений на всех endpoints
- **Secret Management:** Централизованное управление секретами через production Vault
- **Access Control:** API доступен только из внутренней docker сети
- **Health Monitoring:** Полный мониторинг состояния Vault и доступности секретов

### ✅ ТЕХНИЧЕСКИЕ УЛУЧШЕНИЯ
**Обновлены зависимости и устранены конфликты:**
- **Requirements.txt:** Обновлены все зависимости до совместимых стабильных версий
- **Database Config:** Исправлены конфликты в настройках БД (только PostgreSQL для Integration Service)
- **Environment Variables:** Правильная конфигурация переменных окружения для всех сервисов
- **Docker Compose:** Оптимизирована конфигурация для production эксплуатации

### 🎯 PRODUCTION READY STATUS
**Integration Service полностью готов к эксплуатации:**

#### ✅ Критические компоненты работают:
- Vault в production режиме с persistence
- PostgreSQL с полной схемой БД
- Telegram API интеграция (коды + подключение аккаунтов)
- Шифрование сессий через Vault
- Rate limiting и security

#### ✅ Операционная готовность:
- Все API endpoints тестированы и работают
- Health checks показывают здоровое состояние
- Мониторинг и логирование настроены
- Prometheus метрики собираются
- Система готова к масштабированию

#### ✅ Безопасность production уровня:
- Секреты не попадают в репозиторий
- Централизованное управление через Vault
- Audit trail всех операций
- Access control и network isolation

### 🚀 СЛЕДУЮЩИЕ ШАГИ
**Система готова к развитию:**
1. **Массовое подключение аккаунтов** - инфраструктура готова
2. **Реализация отправки сообщений** через подключенные аккаунты  
3. **Фронтенд интерфейс** для управления интеграциями
4. **Backup стратегия** для Vault данных
5. **Автоматический unseal** при перезагрузке сервера

### 📊 ЛОГИ УСПЕШНОЙ РАБОТЫ
```
2025-06-04 21:04:16 - Code sent successfully!
2025-06-04 21:04:16 - Code type: SentCodeTypeApp(length=5)
2025-06-04 21:04:28 - Using active client from memory for sign_in
2025-06-04 21:04:28 - Created TelegramSession with id: 86656856-960d-42ae-9449-868104aed430
```

**🟢 ИТОГОВЫЙ СТАТУС: INTEGRATION SERVICE PRODUCTION READY**