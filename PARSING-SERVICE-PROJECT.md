# PARSING-SERVICE-PROJECT — Описание архитектуры Telegram Parser Service

> **Этот файл содержит актуальное описание микросервиса parsing-service — специализированного сервиса для глубокого парсинга Telegram групп и каналов. Здесь фиксируется архитектура, текущее состояние реализации, интеграции с другими сервисами и планы развития.**

## Назначение и цели

**Telegram Parser Service** — микросервис для сбора максимально полной информации из Telegram по ссылкам на группы и публичные каналы, интегрированный в архитектуру content-factory.xyz.

### Основные цели:
- Глубокий парсинг всех доступных данных из Telegram групп и каналов
- Распределение нагрузки между Telegram-аккаунтами пользователя
- Поиск сообществ по ключевым словам и темам
- Интеграция результатов с другими микросервисами
- Масштабируемость и отказоустойчивость

## Архитектура микросервиса

### Основные компоненты:

#### 1. **parser-api** (FastAPI)
- FastAPI-интерфейс для взаимодействия с пользователями и другими сервисами
- REST API endpoints для управления задачами парсинга
- Интеграция с API Gateway через JWT авторизацию
- Валидация входных данных и форматирование ответов

#### 2. **parser-worker** (Celery)
- Celery-воркеры для асинхронной обработки задач парсинга
- Поддержка параллельной обработки множественных задач
- Автоматическое восстановление при сбоях и ошибках
- Интеграция с RabbitMQ для управления очередями

#### 3. **parser-db** (PostgreSQL)
- Специализированная база данных для хранения:
  - Задач парсинга и их статусов
  - Результатов парсинга (пользователи, сообщения, метаданные)
  - Настроек и конфигураций парсеров
  - Логов и статистики выполнения

#### 4. **parser-state** (Redis)
- Хранение текущих статусов задач и их прогресса
- Управление FloodWait таймерами для аккаунтов
- Кэширование промежуточных результатов парсинга
- Координация между воркерами

#### 5. **proxy-adapter** (будущее)
- Абстрактный слой для подключения Proxy-сервиса
- Возможность задания proxy на уровне аккаунта или задачи
- Готовность к интеграции с будущим proxy-service

## Интеграции с существующими сервисами

### 1. **Integration Service**
- **Получение Telegram-сессий**: Запрос списка доступных аккаунтов пользователя
- **Статусы аккаунтов**: Проверка is_banned, flood_wait_until, is_working
- **Управление сессиями**: Координация использования аккаунтов между сервисами
- **API endpoints**: `/api/v1/telegram/accounts`, `/api/v1/telegram/sessions/{session_id}`

### 2. **Vault Service**
- **Session файлы**: Получение зашифрованных .session файлов Telegram
- **API ключи**: Хранение api_id/api_hash для Telegram API
- **Временные файлы**: Безопасное создание и удаление локальных сессий
- **Путь в Vault**: `kv/integrations/telegram/sessions/{session_id}`

### 3. **API Gateway**
- **Маршрутизация**: Все внешние запросы проходят через Gateway
- **Авторизация**: JWT токены и проверка прав пользователя
- **Rate limiting**: Защита от злоупотреблений и перегрузок
- **Аудит**: Логирование всех API вызовов

### 4. **User Service**
- **Привязка к пользователю**: Все задачи связаны с user_id
- **Лимиты тарифов**: Проверка ограничений на количество задач
- **Биллинг**: Учет расходов на парсинг (в будущем)

## Функциональность (по ТЗ)

### 1. **Интерфейс добавления задач**
- **Endpoint**: `POST /parser/queue`
- **Множественный ввод**: Поддержка массива ссылок
- **Приоритеты**: low, normal, high
- **Валидация**: Проверка формата ссылок и доступности
- **Автоопределение типа**: группа или канал

### 2. **Очередь задач (RabbitMQ)**
- **Структура задачи**:
  - user_id, link, type (group/channel)
  - account_id (назначается динамически)
  - resume_point (для восстановления)
  - status (pending/running/paused/completed/failed)
- **Управление**: Пауза, удаление, приостановка через API
- **Приоритезация**: Обработка высокоприоритетных задач в первую очередь

### 3. **Использование аккаунтов**
- **Получение от Integration Service**: Список доступных сессий
- **Алгоритм распределения**:
  - Только valid && !banned && flood_wait_until < now()
  - Аккаунт с наименьшей нагрузкой (last_used_at)
- **Обработка сбоев**:
  - Переключение на другой аккаунт при бане/флуде
  - Статус waiting при отсутствии аккаунтов
  - Автоматический перезапуск при появлении аккаунтов

### 4. **Парсинг с Telethon**
- **Для групп**: `iter_participants` для получения участников
- **Для каналов**: `get_messages` для сообщений и комментариев
- **Данные группы**: user_id, username, full_name, language_code, status, join_date
- **Данные канала**: сообщения, комментарии, пользователи-комментаторы
- **Общая информация**: title, username, description, participants_count

### 5. **Обработка ошибок и лимитов**
- **Telegram ошибки**: FloodWaitError, SessionExpiredError, AuthKeyError, ChannelPrivateError
- **Rate limiting**: 200-300 запросов без задержки, затем адаптивная пауза
- **Безопасные лимиты**: 100 сообщений/сек, dynamic backoff при превышении
- **Resume functionality**: Сохранение offset и позиции в Redis

### 6. **Поиск сообществ**
- **Endpoint**: `GET /parser/search?q=keywords&offset=0`
- **Методы поиска**: Telethon search_public_chats, GetDialogs
- **Пагинация**: По 100 результатов, поддержка скролла
- **Фильтрация**: Исключение приватных, пустых, недоступных чатов

### 7. **Выгрузка результатов**
- **Endpoint**: `GET /parser/result/{task_id}`
- **Форматы**: CSV, JSON, NDJSON
- **Структура данных**: user_id, username, full_name, status, join_date, source_link
- **Метаданные**: дата парсинга, используемый аккаунт, статус задачи

## Безопасность и мониторинг

### Безопасность:
- **Vault интеграция**: Все .session файлы только через Vault API
- **Временные файлы**: Удаление после завершения работы аккаунта
- **JWT авторизация**: Привязка к user_id через API Gateway
- **Шифрование**: Токены и внутренние ссылки

### Мониторинг:
- **Логирование**: Каждая задача, событие, ошибка
- **Redis статусы**: TTL для статусов задач
- **Prometheus метрики**:
  - parse_tasks_active
  - telegram_accounts_available
  - telegram_accounts_blocked
  - flood_wait_avg
  - fail_rate
  - resume_count

## Технологический стек

- **Язык**: Python 3.11+
- **API Framework**: FastAPI
- **Очереди**: Celery + RabbitMQ
- **Telegram клиент**: Telethon (основной), Pyrogram (fallback)
- **Базы данных**: PostgreSQL (основная), Redis (состояния)
- **Безопасность**: Vault (сессии), HTTPS, JWT
- **Мониторинг**: Prometheus, Grafana, ELK Stack
- **Контейнеризация**: Docker, docker-compose

## Текущее состояние реализации

### ✅ **Существующие компоненты**:
- Базовая FastAPI структура в `/backend/parsing-service/`
- Docker контейнер настроен в docker-compose.yml
- Alembic миграции для PostgreSQL
- Базовые модели парсера (Parser, ParserResult)
- Requirements.txt с основными зависимостями

### ❌ **Требует полной переработки под ТЗ**:
- Текущая реализация — универсальный парсер (web, api, file)
- Нет специализации под Telegram
- Отсутствует интеграция с Integration Service
- Нет работы с RabbitMQ очередями
- Не настроена интеграция с Vault
- Отсутствует Telethon и специфичная логика

### 🔧 **Необходимо реализовать**:
1. Полная переработка под Telegram Parser согласно ТЗ
2. Интеграция с Integration Service для получения аккаунтов
3. Celery воркеры с RabbitMQ
4. Специализированные модели для Telegram данных
5. Telethon клиент с обработкой ошибок
6. Поиск сообществ и выгрузка результатов
7. Мониторинг и безопасность

## Производительность и масштабирование

### Требования:
- **Тестовая нагрузка**: 50 пользователей, 300 аккаунтов, 1000 задач/час
- **Продакшен**: >1000 пользователей, >10k аккаунтов, до 10k задач/час
- **Время отклика API**: <500мс при работе очереди
- **Uptime**: 99.9%

### Архитектурные решения:
- **Асинхронность**: Все задачи через Celery
- **Параллелизм**: Разные чаты — разные задачи
- **Изоляция**: Каждый аккаунт в своем asyncio loop
- **Горизонтальное масштабирование**: Воркеры на нескольких серверах

## Ограничения и защиты

- **Глубина истории**: Максимум 10,000 сообщений по умолчанию
- **Активные задачи**: Ограничение по тарифному плану пользователя
- **Telegram лимиты**: FloodWait + random jitter для избежания блокировок
- **Классификация ошибок**: recoverable vs fatal

## Интеграция с существующей инфраструктурой

### Docker Compose:
- Контейнер уже добавлен в docker-compose.yml
- Volume для данных PostgreSQL
- Сетевая интеграция с backend network

### Мониторинг:
- Prometheus метрики будут добавлены
- Grafana дашборды для отслеживания парсинга
- ELK Stack для логирования ошибок и событий

### Безопасность:
- Интеграция с Vault для получения сессий
- AppRole authentication как в других сервисах
- JWT через API Gateway

## Планы развития

### Phase 1: Базовая реализация
- Переработка под Telegram Parser
- Интеграция с Integration Service
- Базовый парсинг групп и каналов

### Phase 2: Расширенный функционал
- Поиск сообществ по ключевым словам
- Выгрузка в разных форматах
- Обработка resume points

### Phase 3: Масштабирование
- Proxy-сервис интеграция
- Расширенные метрики и алерты
- Оптимизация производительности

---

## Следующие шаги

1. **Анализ и планирование**: Создание детального чек-листа разработки
2. **Переработка архитектуры**: Адаптация под требования ТЗ
3. **Интеграция с сервисами**: Подключение к Integration Service и Vault
4. **Реализация Telegram парсинга**: Telethon клиент и специализированная логика
5. **Тестирование и деплой**: Полная проверка функционала

---

> **Статус проекта**: 🔴 **ТРЕБУЕТ ПОЛНОЙ ПЕРЕРАБОТКИ**  
> Существующая заготовка не соответствует ТЗ и требует полной переработки под специализированный Telegram Parser Service с интеграцией в существующую архитектуру content-factory.xyz. 